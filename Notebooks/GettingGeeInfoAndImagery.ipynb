{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/GettingGeeInfoAndImagery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvLfp4SkgToT"
      },
      "source": [
        "## Install needed software on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZlSmKH9gToW"
      },
      "outputs": [],
      "source": [
        "!pip install mapclassify\n",
        "!pip install geemap\n",
        "!pip install raster_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHxNWk3FgToX"
      },
      "source": [
        "# Getting image statistics and imagery from Google earth engine\n",
        "Google earth engine is a great resource for accessing and processing data. However, to facilitate everyone's processing workflows, Google limits the amount, types, and ways processing can occur. Moreover, to perform larger tasks on Google's servers can require purchasing additional resources. Alteratively, we can download base data and perform task off Google's services. In this notebook we will demonstrate how to stream intermediate products from Google's services for down stream analyses. Later we will use these data to estimate parameters of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKGzW6lMgToY"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import geopandas as gpd, pandas as pd, os, numpy as np\n",
        "import ee, geemap, gdown, os, zipfile\n",
        "import dask, xarray as xr, io, requests, shapely\n",
        "from raster_tools import Raster, general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsb2XFhPgToY"
      },
      "source": [
        "### Authenticate into Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDV6bWqBgToZ"
      },
      "outputs": [],
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-jshogland') #you will want to select your personal cloud project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5guB1AxgToZ"
      },
      "source": [
        "### Get Missoula County"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwnF77bTgToa"
      },
      "outputs": [],
      "source": [
        "if(not os.path.exists('tl_2025_us_county.shp')):\n",
        "    gdown.download('https://www2.census.gov/geo/tiger/TIGER2025/COUNTY/tl_2025_us_county.zip','tl_2025_us_county.zip',quiet=False,fuzzy=True)\n",
        "\n",
        "    with zipfile.ZipFile('tl_2025_us_county.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "\n",
        "cnty=gpd.read_file('tl_2025_us_county.shp').to_crs('EPSG:4326')\n",
        "msl_cnty=cnty[cnty.NAME=='Missoula']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sw0ozT_gToa"
      },
      "source": [
        "### Get the CHM asset\n",
        "Set a filter date that insure you get complete coverage of chm pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlgUIvhigToa"
      },
      "outputs": [],
      "source": [
        "#Get the assest\n",
        "chm=ee.ImageCollection('projects/naip-chm/assets/conus-structure-model')\n",
        "#Filter for a given time span and return the max height value\n",
        "chm_img=chm.filterDate('2021','2024').mosaic() #use dates that cover all acquisitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1FKHnQBgTob"
      },
      "source": [
        "### Get mean estimate for the image\n",
        "Note we will be setting the scale to 10 here to reduce computation. This amounts to sampling within the region of interest and will only have a minor impact on the mean estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJtveKCPgTob"
      },
      "outputs": [],
      "source": [
        "eeftr=geemap.gdf_to_ee(msl_cnty) # create a feature collection from Missoula County\n",
        "\n",
        "ee_dic=geemap.image_mean_value(chm_img,eeftr,10) #use the eeftr to clip the image and set scale to 10 to reduce the number of computations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MCmruo6gTob"
      },
      "source": [
        "### Look at the mean result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq1e69p_gTob"
      },
      "outputs": [],
      "source": [
        "chm_mean=ee_dic.getInfo()\n",
        "chm_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmeceeFygTob"
      },
      "source": [
        "Now look at the (value and time processing) for a scale of 30, 20, 10, 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_amf-wUgTob"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "for s in [30,20,10,5]:\n",
        "    t1=datetime.datetime.now()\n",
        "    ee_dic=geemap.image_mean_value(chm_img,eeftr,s)\n",
        "    info=ee_dic.getInfo()\n",
        "    t2=datetime.datetime.now()\n",
        "    et=t2-t1\n",
        "    print('scale='+str(s), info, et.total_seconds())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0IZOdepgToc"
      },
      "source": [
        "### Create a clipped image for viewing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlHJaIiMgToc"
      },
      "outputs": [],
      "source": [
        "chm_img_clip=chm_img.clip(eeftr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eVbWZOcgToc"
      },
      "source": [
        "## Look at the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsUpKggmgToc"
      },
      "outputs": [],
      "source": [
        "m=geemap.Map()\n",
        "m.set_center(lon=-113.9940,lat=46.8721,zoom=8)\n",
        "m.add_basemap(basemap='ESRI.WorldImagery')\n",
        "\n",
        "m.add_gdf(msl_cnty,layer_name='Missoula County',)\n",
        "m.addLayer(\n",
        "    chm_img_clip,\n",
        "    {\"min\": 0, \"max\": 3000,\"palette\":'viridis'},\n",
        "    'CHM',\n",
        ")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ieeBMgxgToc"
      },
      "source": [
        "## Create definitions to iteratively download imagery from Earth Engine\n",
        "This code is a little detailed and will send many requests to earth engine to accommodate their quota limits. Specifically, each chunk within the raster dataset will be a request for a image from Google earth image. So what are image chunks? Chunks are subsets of a large image that are used within Raster Tools to schedule processing. Each chunk is processed separately to accommodate parallel processing. In this case we are using dask and Raster Tools to parallelize the download of the medoid image from Google Earth image. When we save out the final image it will also get saved in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJgHocxugToc"
      },
      "outputs": [],
      "source": [
        "def _convert_array2(x,bnds,rws,clms):\n",
        "    outarr=np.zeros((bnds,rws,clms),dtype='f8')\n",
        "    for r in range(x.shape[0]):\n",
        "        for c in range(x.shape[1]):\n",
        "            vls=x[r,c]\n",
        "            for b in range(bnds):\n",
        "                outarr[b,r,c]=vls[b]\n",
        "\n",
        "    return outarr\n",
        "\n",
        "def _get_block(ee_object,ee_geo,bnds,rws,clms):\n",
        "    success=True\n",
        "    url=ee_object.getDownloadURL({'format':'NPY','region':ee_geo})\n",
        "    try:\n",
        "        #print('downloading',url)\n",
        "        resp=requests.get(url)\n",
        "        data=np.load(io.BytesIO(resp.content))\n",
        "        #print('reformatting data')\n",
        "        outarr =_convert_array2(data,bnds,rws,clms)\n",
        "        #print('finished')\n",
        "    except Exception as e:\n",
        "        #print(e,url)\n",
        "        outarr=np.zeros((bnds,rws,clms))\n",
        "        success=False\n",
        "    finally:\n",
        "        return success,outarr,url\n",
        "\n",
        "def _get_block_values2(ee_object,xmin,ymax,res,oprj,retry=2,block_info=None):\n",
        "    bo_info=block_info[None]\n",
        "    aloc=bo_info['array-location']\n",
        "    bnds,rws,clms=bo_info['chunk-shape']\n",
        "    xrng=aloc[2]\n",
        "    yrng=aloc[1]\n",
        "    xmin2=xmin+(xrng[0]*res)\n",
        "    xmax2=xmin+(xrng[1]*res)\n",
        "    ymax2=ymax-(yrng[0]*res)\n",
        "    ymin2=ymax-(yrng[1]*res)\n",
        "    ply=[\n",
        "        [xmin2,ymin2],\n",
        "        [xmin2,ymax2],\n",
        "        [xmax2,ymax2],\n",
        "        [xmax2,ymin2],\n",
        "        [xmin2,ymin2]\n",
        "    ]\n",
        "    tbb=shapely.Polygon(ply)\n",
        "    tgdf=gpd.GeoSeries(tbb,crs=oprj).buffer(-res/2.0)\n",
        "    g=tgdf.to_crs('EPSG:4326').geometry.iloc[0]\n",
        "    xx,yy=g.exterior.coords.xy\n",
        "    x=list(xx)\n",
        "    y=list(yy)\n",
        "    ee_geo=ee.Geometry.Polygon(tuple(zip(x,y)))\n",
        "    cnt=0\n",
        "    success,outarr,url=_get_block(ee_object,ee_geo,bnds,rws,clms)\n",
        "    #build a loop to get data in the case of server error\n",
        "    while (success==False):\n",
        "        if(cnt>retry):\n",
        "            break\n",
        "        print('Retry',cnt+1)\n",
        "        success,outarr,url=_get_block(ee_object,ee_geo,bnds,rws,clms)\n",
        "        cnt+=1\n",
        "\n",
        "    if(success==False):\n",
        "        print(\"Problem with url\",url)\n",
        "\n",
        "    return outarr\n",
        "\n",
        "\n",
        "\n",
        "def get_raster(gdf, ee_object,dvs=2048):\n",
        "    '''\n",
        "    creates a raster dataset of specified resolution from point clouds\n",
        "\n",
        "    gdf: geodataframe from build_extent function\n",
        "    ee_object: earth engine image object\n",
        "    dvs: int of number of cells of the length of a square chunk\n",
        "\n",
        "    return: Raster of image values\n",
        "    '''\n",
        "    prj=ee_object.projection()\n",
        "    oprj=prj.crs().getInfo()\n",
        "    xmin,ymin,xmax,ymax=gdf.to_crs(oprj).total_bounds.astype('int32')\n",
        "    res=prj.nominalScale().getInfo()\n",
        "    xchs=int((xmax-xmin)/(dvs*res))+1\n",
        "    ychs=int((ymax-ymin)/(dvs*res))+1\n",
        "    xsteps=np.arange(xmin,xmin+(xchs*dvs*res),res)\n",
        "    ysteps=np.arange(ymax,ymax-(ychs*dvs*res),-res)\n",
        "\n",
        "\n",
        "    #make chunks\n",
        "    bnds = ee_object.bandNames().getInfo()\n",
        "\n",
        "    xchunk=tuple([dvs]*xchs)\n",
        "    ychunk=tuple([dvs]*ychs)\n",
        "\n",
        "    tda=dask.array.map_blocks(_get_block_values2,ee_object,xmin,ymax,res,oprj,chunks=((len(bnds)),ychunk,xchunk),dtype=float)\n",
        "    xrs=xr.DataArray(tda,coords={'band':bnds,'y':ysteps,'x':xsteps})\n",
        "    return xrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BrKOusggToc"
      },
      "source": [
        "### When creating the image you must specify a projection and set a scale. Chunk size 2048 is also very important to address memory issues on GEE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ow2vh-SgToc"
      },
      "outputs": [],
      "source": [
        "chm_img_prg=chm_img_clip.setDefaultProjection(crs='EPSG:5070',scale=1) # set the projection and scale of the output image\n",
        "chm_loc=get_raster(msl_cnty,chm_img_prg,2048).astype('uint16')\n",
        "chm_loc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfL7XKJ2gToc"
      },
      "source": [
        "### This will make a very large image (>22.34 GB).\n",
        "Let's download the values for a small area and plot them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RT_ji9AgToc"
      },
      "outputs": [],
      "source": [
        "chm_loc[:,10000:12048,10000:12048].plot(figsize=(15,15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_h8HX2tgTod"
      },
      "source": [
        "### What would happen if we changed the resolution to 10 meters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTScIpQdgTod"
      },
      "outputs": [],
      "source": [
        "chm_img_prg2=chm_img_clip.setDefaultProjection(crs='EPSG:5070',scale=10) # set the projection and scale of the output image\n",
        "chm_loc2=get_raster(msl_cnty,chm_img_prg2,2048).astype('uint16')\n",
        "chm_loc2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptrKleufgTod"
      },
      "source": [
        "### We now have a much smaller dataset that has been resampled based on nearest neighbors to a spatial resolution of 10m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvD9-ZWZgTod"
      },
      "outputs": [],
      "source": [
        "chm_loc2[:,1000:1205,1000:1205].plot(figsize=(15,15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ww3n1gkgTod"
      },
      "source": [
        "### Let's save the 10m image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAnq8rUMgTod"
      },
      "outputs": [],
      "source": [
        "rs=Raster(chm_loc2).set_crs('EPSG:5070').load()\n",
        "rs.save('chm.tif',tiled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1lNdt_ggTod"
      },
      "source": [
        "## Now let's get  RAP3 surfaces for the 30m collection\n",
        "Create the asset. Note the other rap assets are commented out below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz3YrybpgTod"
      },
      "outputs": [],
      "source": [
        "#Vegetation Cover 30m\n",
        "veg_yearly_30m = ee.ImageCollection(\"projects/rap-data-365417/assets/vegetation-cover-v3\") # Plant functional types\n",
        "\n",
        "# #Vegetation Cover and Canopy Gap 10m\n",
        "# veg_yearly_10m = ee.ImageCollection('projects/rap-data-365417/assets/vegetation-cover-10m') # Plant functional types\n",
        "# iag_yearly_10m = ee.ImageCollection('projects/rap-data-365417/assets/invasive-annual-grass-cover-10m') # Invasive annual grasses\n",
        "# sagebrush_yearly_10m = ee.ImageCollection('projects/rap-data-365417/assets/sagebrush-cover-10m') # Sagebrush (Artemisia spp.)\n",
        "# pj_yearly_10m = ee.ImageCollection('projects/rap-data-365417/assets/pj-cover-10m') # Pinyon-juniper\n",
        "# gap_yearly_10m = ee.ImageCollection('projects/rap-data-365417/assets/gap-cover-10m') # Canopy gaps\n",
        "\n",
        "# #Rangeland Production 30m\n",
        "# npp_yearly = ee.ImageCollection(\"projects/rap-data-365417/assets/npp-partitioned-v3\") # Net primary production (yearly)\n",
        "# npp_16d = ee.ImageCollection(\"projects/rap-data-365417/assets/npp-partitioned-16day-v3\") # Net primary production (16-day)\n",
        "# npp_16d_prov = ee.ImageCollection(\"projects/rap-data-365417/assets/npp-partitioned-16day-v3-provisional\") # Net primary production (16-day) provisional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2qUjamkgTof"
      },
      "source": [
        "### Select the start and end year to filer the image collection and summarize mean the mean value for each image band within Missoula County"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9U5QVHYBgTof"
      },
      "outputs": [],
      "source": [
        "yr_start='2021'\n",
        "yr_end='2022'\n",
        "\n",
        "eeftr=geemap.gdf_to_ee(msl_cnty)\n",
        "\n",
        "rap_img=veg_yearly_30m.filterDate(yr_start,yr_end).mosaic()\n",
        "ee_dic=geemap.image_mean_value(rap_img,region=eeftr,scale=30)\n",
        "rap_means=ee_dic.getInfo()\n",
        "rap_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBpmhzj0gTof"
      },
      "source": [
        "## Now let's get the embeddings values\n",
        "### Get the asset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUoTT8Q3gTof"
      },
      "outputs": [],
      "source": [
        "emb=ee.ImageCollection(\"GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL\")\n",
        "yr_start='2023-01-01'\n",
        "yr_end='2024-01-01'\n",
        "emb_img=emb.filterDate(yr_start,yr_end).mosaic()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7zKCPrCgTof"
      },
      "source": [
        "### Get mean values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHg4ZrK5gToi"
      },
      "outputs": [],
      "source": [
        "eeftr=geemap.gdf_to_ee(msl_cnty)\n",
        "\n",
        "ee_dic=geemap.image_mean_value(emb_img,region=eeftr,scale=30)\n",
        "emb_means=ee_dic.getInfo()\n",
        "emb_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi9McxHPgToi"
      },
      "source": [
        "### Add all mean values to the Missoula geodataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3RBGllzgToi"
      },
      "outputs": [],
      "source": [
        "msl_cnty=msl_cnty.join(pd.DataFrame(chm_mean|rap_means|emb_means,index=msl_cnty.index))\n",
        "msl_cnty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGUbi1BpgToj"
      },
      "source": [
        "## Getting point data from GEE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9YYimy_gToj"
      },
      "source": [
        "### Create point locations within the Missoula county boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsgjnehFgToj"
      },
      "outputs": [],
      "source": [
        "pnts=gpd.GeoDataFrame(geometry=msl_cnty.sample_points(100).explode(),crs=msl_cnty.crs) #random points in Missoula county\n",
        "pnts.explore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyAbACDHgToj"
      },
      "source": [
        "### Create definition to extract values at those point locations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL2qyiMCgToj"
      },
      "outputs": [],
      "source": [
        "def _get_tiles(gdf,ntiles):\n",
        "  '''\n",
        "  splits the area into tiles to address quota limits\n",
        "  gdf = (geodataframe) the points geodata frame used to create bounary of the study area\n",
        "  ntiles= (int) the number of tiles to make\n",
        "  '''\n",
        "  chul=gpd.GeoSeries(gdf.union_all().convex_hull,crs=gdf.crs)\n",
        "  xmin,ymin,xmax,ymax=chul.total_bounds\n",
        "  sp=(np.sqrt(chul.area/ntiles))[0]\n",
        "  sp2=(sp/2)\n",
        "  xs=np.arange(xmin-sp2,xmax+sp2,sp)\n",
        "  ys=np.arange(ymin-sp2,ymax+sp2,sp)\n",
        "  xv, yv = np.meshgrid(xs, ys)\n",
        "  xv = xv.flatten()\n",
        "  yv = yv.flatten()\n",
        "  pnts = gpd.GeoSeries(gpd.points_from_xy(x=xv, y=yv),crs=gdf.crs)\n",
        "  buff = pnts.buffer(sp2,cap_style='square')\n",
        "  buff = buff[buff.intersects(gdf.union_all())]\n",
        "  return buff\n",
        "\n",
        "def extract_data(gdf,img,ntiles,stats='FIRST',scale=30):\n",
        "    '''\n",
        "    Iteratively calls EE and extracts data from the image\n",
        "    gdf = (geodataframe) of features used to extract values\n",
        "    img = (ee image object) ee image to extract values from\n",
        "    ntiles = (int) number of tiles used to extract data at a time\n",
        "    stats= (string) name of the ee static (e.g., FIRST, MEAN, MAX, MIN, MEDIAN, etc.)\n",
        "\n",
        "    returns a Dataframe of values (one record for each observation in the gdf)\n",
        "    '''\n",
        "    tls=_get_tiles(gdf,ntiles)\n",
        "    ogdf=gdf.copy()\n",
        "    for t in tls:\n",
        "        sel=ogdf.intersects(t)\n",
        "        sdf=ogdf[['geometry']][sel]\n",
        "\n",
        "        #use try and except catch errors\n",
        "        try:\n",
        "            fc=geemap.gdf_to_ee(sdf) #convert your subset geodataframe into a ee feature class object\n",
        "            outfc=geemap.extract_values_to_points(fc,img,stats_type=stats,scale=scale) #extract the image values for each point location.\n",
        "            ogdf2=geemap.ee_to_gdf(outfc).drop(['geometry'],axis=1) #convert your output ee object into a geodataframe\n",
        "            column_names=ogdf2.columns\n",
        "            ogdf.loc[sel,column_names]=ogdf2.values #update records of our geodataframe\n",
        "        except Exception as e:\n",
        "            print('Error: ',e)\n",
        "\n",
        "    return ogdf #return the geodataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQzd-7LtgToj"
      },
      "source": [
        "### Get GEE Image point data for the 100 locations\n",
        "Note, that the CHM dataframe has a column named first while the other dataframes have columns named after the bands. This is because of the way GEE coded their extraction procedure and because CHM only has one band."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qlh6DfagToj"
      },
      "outputs": [],
      "source": [
        "chm_vls=extract_data(pnts,chm_img,5)\n",
        "chm_vls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdnipyKsgToj"
      },
      "outputs": [],
      "source": [
        "rap_vls=extract_data(pnts,rap_img,5)\n",
        "rap_vls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjTjPaGkgToj"
      },
      "outputs": [],
      "source": [
        "emb_vls=extract_data(pnts,emb_img,5)\n",
        "emb_vls"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rstools",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/kernel_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcZNhvYmw_7v"
   },
   "source": [
    "# Estimating kernel weights using PCA and creating optimal predictor surfaces\n",
    "## In this notebook we will explore the use of Raster Tools and Scikit learn functions to project predictor surfaces into orthogonal space for modeling purposes. A few key objectives of using this approach:\n",
    "- Determine and use the optimal cell weights of a convolution kernel (user defined size) that can be used to transform a given image and its bands into a subset of surfaces that explain a user specified amount of the variation in the image data.\n",
    "- Efficiently create orthogonal predictor surfaces that account for band and spatial covariation.\n",
    "- Create predictor surfaces that highlight various attributes within the data.\n",
    "### The approach\n",
    "- Use sampling to create training sets\n",
    "- Scale input rasters to unit variance\n",
    "- Perform PCA on scaled training sets that include all input cell values for the cells within a user specified convolution kernel\n",
    "- Center scaled kernel cell values, multiply PCA score weights by centered values, and sum values within the kernel to perform the convolution\n",
    "- Optionally, rescale PCA transformed values to a specified bit depth for storage and downstream analyses\n",
    "\n",
    "John Hogland 12/6/20024\n",
    "\n",
    "#### Study area for this example includes portions of the Custer Gallatin Nation Forest\n",
    "\n",
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4_t0-07xMKD"
   },
   "outputs": [],
   "source": [
    "!pip install mapclassify\n",
    "!pip install osmnx\n",
    "!pip install raster_tools\n",
    "!pip install planetary-computer\n",
    "!pip install pystac-client\n",
    "!pip install stackstac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5s6NvQ3xbTe"
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uuRURE7w_7w"
   },
   "outputs": [],
   "source": [
    "import numpy as np, os, geopandas as gpd, pandas as pd, osmnx as ox, pystac_client, planetary_computer, stackstac\n",
    "from raster_tools import Raster, general\n",
    "from raster_tools import raster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "### Multispectral remotely sensed datasets are commonly used as predictor variables in many classification, regression, and clustering models. Often these data are highly correlated and covary across bands and x and y space. For compression, storage, and predictive modeling purposes it is often advantageous to project those data along shared axes of covariance to create independent transformed variables. One common technique used to project data along shared covariance axes is a principal component analysis (PCA). \n",
    "### For many remote sensing projects, PCAs have successfully been used to project data onto orthogonal axes called components and select subsets of components that account for a known amount of variation to reduce the dimensionality. However, contemporary remote sensing projects go beyond using just the band values acquired at a given location within an image (the cell). For example, computer visions and convolution neural networks include neighboring cell values that define textural aspects of an image for a specific region around a location (kernel). Defining and using kernels to enhance, smooth, and quantify edges have provided key insights into shapes, boundaries, and various textural attributes contained within an image. However, like multispectral band cell values, texture can covary across both cells and bands. Additionally, the total number of potential kernels that can be defined and used to quantify texture are infinite.\n",
    "### This has led some to a priori define kernels known to capture specific textural relationships and apply those kernels across remotely sensed data to develop predictor variables. Yet, others use iteration and deep learning to optimally determine kernel weights. However, few remote sensing projects have addressed the issues of covariance in neighboring cell values across image bands. Moreover, no studies have leveraged PCA component scores to define kernel weights.\n",
    "### In this example we explore the use of a PCA to project multispectral imagery along orthogonal axes derived from both band and neighboring cell values. Our procedure automates the selection of optimal kernel weights for multidimensional convolution kernels based on principal component scores and the proportion of the variation (information) explained by each component. The spatial extent of our study includes portions of the Custer Gallatin National Forest located in southeastern Montana, USA (Figure 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzrUU7gnw_7x"
   },
   "source": [
    "#### Get the boundary data for portions of the Custer Gallatin National Forest and create a interactive location map of the study (Figure 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdV_EZQgw_7x"
   },
   "outputs": [],
   "source": [
    "#use OpenStreetMaps to get the boundary of the NF\n",
    "nf=ox.geocode_to_gdf('Custer Gallatin National Forest, MT, USA')\n",
    "\n",
    "#get first polygon of the NF\n",
    "nfe=nf.explode()\n",
    "nf1=gpd.GeoSeries(nfe.geometry.iloc[10],crs=nf.crs)\n",
    "\n",
    "#project to Albers equal area\n",
    "nf1p=nf1.to_crs(5070)\n",
    "\n",
    "#Visualize the nf1 and sample locations\n",
    "m=nf1p.explore()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 1.__ Interactive location map of the study area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### To project Landsat 8 imagery to independent component surfaces (ICSs) we will implement a multistep approach. In Step One we downloaded part of a Landsat scene for the area around the Custer Gallatin Nation Forest (Figure 1) from Planetary Computer. For Step Two we created a series of functions to extract the values from a systematic random sample of cell locations within the Landsat image and surrounding kernel cell values. In Step Three we flattened kernel cell values by band for each sampled location and performed a PCA. For Step Four we extracted component scores for components that accounted for 95% of the variation in the data. Finally, in Step Five, we applied component scores to kernel cell values within each Landsat band. To perform these steps, we created a series of python functions that utilize Scikit Learn and Raster Tools application programming interface (API). Relevant functions can be found within the following section/function bulleted list:\n",
    "- Get Landsat 8 Imagery\n",
    "    - Create download definition\n",
    "        - Mosaic_stac\n",
    "        - Get_stac_data\n",
    "    - Download the data\n",
    "- Visualize the boundary and imagery\n",
    "- Convolution PCA\n",
    "    - Create Definitions to perform convolution PCA\n",
    "        - _conv_pca\n",
    "        - _expand_for_kernel\n",
    "        - _sys_sample_image\n",
    "        - conv_pca\n",
    "    - Perform pca convolution analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU3LLnKsw_7x"
   },
   "source": [
    "### Get Landsat 8 Imagery\n",
    "Create download definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FvPl1L4w_7x"
   },
   "outputs": [],
   "source": [
    "#create definition to mosaic stac data\n",
    "def mosaic_stac(xr):\n",
    "    return stackstac.mosaic(xr)\n",
    "\n",
    "#create definition to extract stac data\n",
    "def get_stac_data(geo,url=\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"sentinel-2-l2a\",res=30,crs=5070,**kwarg):\n",
    "    '''\n",
    "    gets tiled data from planetary computer as a dask backed xarray that intersects the geometry of the point, line, or polygon\n",
    "\n",
    "    geo = (polygon) geometry bounding box (WGS84)\n",
    "    url = (string) base url to planetary computer https://planetarycomputer.microsoft.com/api/stac/v1\n",
    "    name = (string) catelog resource\n",
    "    qry =  (dictoinary) of property values {'eo:cloud_cover':{'lt':1}}\n",
    "    res = (tuple of numbers) output resolution (x,y)\n",
    "    crs = (int) output crs\n",
    "    dt = (string) data time intervale e.g., one month: 2023-06, range: 2023-06-02/2023-06-17\n",
    "    limit = (int) max number of items to return\n",
    "\n",
    "    returns (xarray data array and stac item catalog)\n",
    "    '''\n",
    "    catalog = pystac_client.Client.open(url, modifier=planetary_computer.sign_inplace)\n",
    "    srch = catalog.search(collections=name, intersects=geo, **kwarg)\n",
    "    ic = srch.item_collection()\n",
    "    if(len(ic.items)>0):\n",
    "        xra = stackstac.stack(ic,resolution=res,epsg=crs)\n",
    "        xra = mosaic_stac(xra)\n",
    "    else:\n",
    "        xra=None\n",
    "\n",
    "    return xra,ic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lORu4UOw_7y"
   },
   "source": [
    "Download the data and create a raster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIS1S--Fw_7y"
   },
   "outputs": [],
   "source": [
    "#get stac data landsat data\n",
    "if(not os.path.exists('ls82016.tif')):\n",
    "    xmin,ymin,xmax,ymax=nf1p.buffer(200).total_bounds\n",
    "    ls30, ic =get_stac_data(nf1.geometry[0],\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"landsat-c2-l2\",res=30,crs=5070,datetime='2016-06-15/2016-06-30',query={'eo:cloud_cover':{'lt':10},'platform':{'eq':'landsat-8'}},limit=1000)\n",
    "    ls30s=Raster(ls30.sel(band=['red', 'green', 'blue','nir08', 'lwir11','swir16', 'swir22'],x=slice(xmin,xmax),y=slice(ymax,ymin)))\n",
    "    ls30s=ls30s.save('ls82016.tif')\n",
    "\n",
    "ls30s=Raster('ls82016.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSnEqLbbw_7z"
   },
   "source": [
    "### Visualize the boundary and  imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=nf1p.plot(edgecolor='red',facecolor='none',figsize=(15,10))\n",
    "p=ls30s.get_bands([1,2,3]).xdata.plot.imshow(ax=p,robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 2.__ Overlay of Landsat 8 image subset (RGB bands) and the study area boundary outline in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uK7owb-w_7z"
   },
   "source": [
    "### Perform convolution PCA\n",
    "Create definitions to sample the data, generate weights, and perform convolution analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1ZotYGhw_7z"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numba as nb\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _conv_pca(x,cmp_, m_, size):\n",
    "    '''\n",
    "    Performs the convolution given a array, component scores, means, and kernel size using dask's map_overlap function\n",
    "    x=(numpy array) of data\n",
    "    cmp_= (numpy array) component scores from sklearn PCA procedure\n",
    "    m_= (numpy array) mean values from sklearn PCA procedure\n",
    "    size= (int) width of the kernel\n",
    "\n",
    "    returns a numpy array of correct shape for PCA transformation\n",
    "    '''\n",
    "    bnd,rws,clms=x.shape\n",
    "    hs=int(size/2)\n",
    "    outarr=np.empty((cmp_.shape[0],rws,clms))\n",
    "    for ri in range(hs,rws-hs):\n",
    "        sr=ri-hs\n",
    "        for ci in range(hs,clms-hs):\n",
    "            sc=ci-hs\n",
    "            vls=x[:,sr:sr+size,sc:sc+size].flatten()\n",
    "            for b in range(cmp_.shape[0]):\n",
    "                vls2=((vls-m_)*cmp_[b,:]).sum() #removed the centering piece in standard scaler it is done here\n",
    "                outarr[b,ri,ci]=vls2\n",
    "\n",
    "    return outarr\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _expand_for_kernel(isys,isxs,wsize):#,mr,mc):\n",
    "    '''\n",
    "    Extracts values for kernel cells. Cells indices falling on the boundary of the image are moved in one index value.\n",
    "    isys=array of row index locations\n",
    "    isxs=array of column index locations\n",
    "    wsize=width of the kernel\n",
    "    mr=max row index\n",
    "    mc=max column index\n",
    "\n",
    "    returns two new lists of index values that can be used to extract coordinate from an xarray data array\n",
    "    '''\n",
    "    hw=int(wsize/2)\n",
    "    isys2=np.zeros(isys.shape[0]*wsize,dtype='int32')\n",
    "    isxs2=np.zeros(isxs.shape[0]*wsize,dtype='int32')\n",
    "    for r in range(isys.shape[0]):\n",
    "        cvl=isys[r]\n",
    "        cvlm=cvl-hw\n",
    "        for r2 in range(wsize):\n",
    "            nr=r2+r*wsize\n",
    "            nvl=cvlm+r2\n",
    "            isys2[nr]=nvl\n",
    "\n",
    "    for c in range(isxs.shape[0]):\n",
    "        cvl=isxs[c]\n",
    "        cvlm=cvl-hw\n",
    "        for c2 in range(wsize):\n",
    "            nc=c2+c*wsize\n",
    "            nvl=cvlm+c2\n",
    "            isxs2[nc]=nvl\n",
    "\n",
    "    return isys2,isxs2\n",
    "\n",
    "def _sys_sample_image(rs,p,wsize=0):\n",
    "    '''\n",
    "    Creates a systematic sample of an image given a percent of cells sampled.\n",
    "    rs = Raster object to be sampled\n",
    "    p = percent of pixels to sample\n",
    "    wsize=(int) width of a square kernel in cells if using convolution type analyses\n",
    "\n",
    "    returns a 2d array of cell values rows=point centroid columns= band values\n",
    "    if using kernels columns correspond to kernel cell values for each point\n",
    "    '''\n",
    "    bnds,rws,clms=rs.shape\n",
    "    ys=rs.y\n",
    "    xs=rs.x\n",
    "    psq=np.sqrt(p)\n",
    "    sr=int(rws/(rws*psq))\n",
    "    sc=int(clms/(clms*psq))\n",
    "    rstr=int(np.random.rand()*sr)\n",
    "    rstc=int(np.random.rand()*sc)\n",
    "    isys=np.arange(rstr+wsize,rws-wsize,sr)\n",
    "    isxs=np.arange(rstc+wsize,clms-wsize,sc)\n",
    "\n",
    "    if(wsize>0):\n",
    "        isys,isxs=_expand_for_kernel(isys,isxs,wsize)#,rws,clms)\n",
    "\n",
    "    sys=ys[isys]\n",
    "    sxs=xs[isxs]\n",
    "    sel=rs.xdata.sel(x=sxs,y=sys)\n",
    "    bnds,rws,clms=sel.shape\n",
    "    \n",
    "    if(wsize>0):\n",
    "        bnds=bnds*wsize*wsize\n",
    "        rws=int(rws/wsize)\n",
    "        clms=int(clms/wsize)\n",
    "\n",
    "    #sel2=sel[sel!=rs.null_value]\n",
    "\n",
    "    # lx,ly=np.meshgrid(sel.x,sel.y) #if you want to look at the location of each sampled cell\n",
    "    # pnts=gpd.GeoSeries(gpd.points_from_xy(x=lx.flatten(),y=ly.flatten(),crs=rs.crs))\n",
    "    vls=np.moveaxis(sel.values,0,-1).flatten().reshape((rws*clms,bnds))\n",
    "    df=pd.DataFrame(vls)\n",
    "    vls=df[df!=rs.null_value].dropna().values\n",
    "\n",
    "    return vls#,  sel#, pnts\n",
    "\n",
    "def conv_pca(rs,prc=0.9,smp=0.01,ksize=0,output_bit_depth=None):\n",
    "    '''\n",
    "    determines convolution kernel weights for an optimal raster projection and returns a transformed raster\n",
    "    using those weights. Weights are derived from a PCA analysis of each kernel cell value. Kernel cell\n",
    "    values are extracted for each band in the rs stack.\n",
    "\n",
    "    rs=(Raster) input raster object\n",
    "    wsize=(int) window diameter for a square kernel measured in cells\n",
    "    prc=(float) the proportion of variation in the data kept in the final raster dataset (0-1)\n",
    "    smp=(float) the proportion of data used to build the transformation (training data - systematic random sample of location)\n",
    "    ksize=(int) kernel width to use measured in cells\n",
    "    output_bit_depths=(int) optional parameter used to scale the analysis outputs to a specified bit depth (e.g., 8,16,32).\n",
    "    By default (None) output values will not be scaled\n",
    "\n",
    "    returns a projected raster object and the pca object\n",
    "    '''\n",
    "    #scale values using a sample\n",
    "    vls=_sys_sample_image(rs,p=smp)\n",
    "    ss=StandardScaler(with_mean=False)\n",
    "    ss.fit(vls)\n",
    "\n",
    "    #apply the scaling to the input raster\n",
    "    ss_mdl = general.ModelPredictAdaptor(ss,'transform')\n",
    "    nch=(rs.nbands,*rs.xdata.chunks[1:])\n",
    "    sc_pred_rs=rs.model_predict(ss_mdl,rs.nbands).chunk(nch)\n",
    "\n",
    "    #perform pca using a sample of the scaled raster values\n",
    "    vls2=_sys_sample_image(sc_pred_rs,p=smp,wsize=ksize)\n",
    "    \n",
    "    pca=PCA()\n",
    "    pca.fit(vls2)\n",
    "    #determine number of components to use\n",
    "    ev=pca.explained_variance_ratio_\n",
    "    sev=0\n",
    "    for i in range(ev.shape[0]):\n",
    "        e=ev[i]\n",
    "        sev+=e\n",
    "        if sev>prc:\n",
    "            break\n",
    "    kc=i+1 #add one to address 0 start\n",
    "\n",
    "    #extract component scores for _conv_pca method\n",
    "    kdf=pca.components_[0:kc,:] #scores,component (rows have weightings)\n",
    "    hw=int(ksize/2)\n",
    "\n",
    "    nch=sc_pred_rs.data.chunks\n",
    "    och=list(nch)\n",
    "    och[0]=(kc,)\n",
    "    och[1]=tuple(np.array(och[1])+hw*2)\n",
    "    och[2]=tuple(np.array(och[2])+hw*2)\n",
    "\n",
    "    #apply _conv_pca to map_overlap function\n",
    "    darr=sc_pred_rs.data.map_overlap(\n",
    "        _conv_pca,\n",
    "        depth={0: 0, 1: hw, 2: hw},\n",
    "        chunks=och,\n",
    "        boundary=np.nan,\n",
    "        dtype='f8',\n",
    "        meta=np.array((),dtype='f8'),\n",
    "        cmp_=kdf,\n",
    "        m_=pca.mean_,\n",
    "        size=ksize\n",
    "    )\n",
    "    #convert dask array back to a raster\n",
    "    cmp_rs=raster.data_to_raster(darr,x=sc_pred_rs.x,y=sc_pred_rs.y,affine=sc_pred_rs.affine,crs=sc_pred_rs.crs,nv=sc_pred_rs.null_value).chunk((1,*darr.chunks[1:]))\n",
    "\n",
    "    #scale projected raster to bit depth if specified\n",
    "    if(not output_bit_depth is None):\n",
    "        pcasvls=pca.transform(vls2)[:,0:kc]\n",
    "        mmsc=MinMaxScaler()\n",
    "        mmsc.fit(pcasvls)\n",
    "        mmsc_mdl=general.ModelPredictAdaptor(mmsc,'transform')\n",
    "        cmp_rs=(cmp_rs.model_predict(mmsc_mdl,cmp_rs.nbands)*(2**output_bit_depth-1)).astype('uint'+str(output_bit_depth))\n",
    "\n",
    "    return cmp_rs,pca\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the PCA convolution process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform the pca convolution process on the landsat image; kernel size 5 by 5, output bit depth 16.\n",
    "# This can be any size kernel. I have tried up to a 15 by 15.\n",
    "ksize=5\n",
    "conv_rs,pca=conv_pca(ls30s,prc=0.95,smp=0.1,ksize=ksize,output_bit_depth=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Using our described approach, we accounted for 95% of the variation within the image using the first eleven principal components (Figure 3). Component convolution kernel weights (Display 1) highlight the linear relationships among both Landsat image bands and neighboring kernel cell values. For a random systematic sample of approximately 10% of the first 3 component values, five unique clusters of information with varying trends appear in component space (Figure 4). \n",
    "### To transform our Landsat 8 image into 11 ICSs (Figure 5) required processing 77, 5 by 5 convolution kernels. To explain the remaining 5% of the variation in the data, an additional 1148 convolution kernels would need to be processed. Using a threshold of 95% of the variation within the data substantially reduced the total amount of processing time needed to create ICSs while simultaneously keeping the vast majority of information within the data. Moreover, implementing this processing within the Raster Tools processing architecture was easy and extremely efficient.\n",
    "### Visually, each ICS highlights a different aspect of the data within the image (Figure 5). Within each ICS, linear combinations of both hue and texture are highlighted to varying degrees and are projected such that each surface is independent, which can be ideal for downstream predictive modeling.\n",
    "### The following processing steps were used to create Figures 3-5 and Display 1.\n",
    "- Visualize % variation\n",
    "- Look at kernel weights\n",
    "- Look at 3d plot\n",
    "- Visualize the PCA convolution raster surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr_NL1ggw_70"
   },
   "source": [
    "### - Visualize % variation explained in each band (component) of the transformed image (Figure 3).\n",
    "#### The number of bands correspond to the number of components that account for 95% of the variation in the 5 by 5 convolved image. Note that most of the variation/information in the data is explained in the first 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8bYI_UXw_70"
   },
   "outputs": [],
   "source": [
    "var_exp=pd.DataFrame(pca.explained_variance_ratio_[:conv_rs.nbands])\n",
    "print('Total % variance explained in components =',var_exp.sum().values[0])\n",
    "p=var_exp.plot(kind='barh',title='Components by % Variation Explained', xlabel='% Variation', ylabel='Component', figsize=(15,8),legend=False).invert_yaxis()\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 3.__ Proportion of variation explained in each principal component. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Look at the kernel weights for each selected component (Display 1).\n",
    "#### Each component is made of the summation of 7 convolution kernels with the following weights. Convolution weights are applied to the centered and scaled input surface values of each band within the specified kernel of the input raster surface (ls30s in our example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw=pca.components_[0:conv_rs.nbands,:]\n",
    "for k in range(kw.shape[0]):\n",
    "    krs=kw[k].reshape((ls30s.nbands,ksize,ksize))\n",
    "    print('\\nWeights for component',k)\n",
    "    print(krs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display 1.__ Kernel weights for each component of the PCA convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Look at a 3d plot of the first 3 components for systematic random locations using 10% of the data. (Figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "#get a sample of the PCA convolution raster values\n",
    "vls=_sys_sample_image(conv_rs,0.1,1) #convolve 1 to remove convolved image edge effect in sampling \n",
    "df=pd.DataFrame(vls)\n",
    "print('n =', df.shape[0])\n",
    "fig = px.scatter_3d(df, x=0, y=1, z=2\n",
    "              ,width=1500,height=800)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 4.__ A 3 dimensional representation of the first 3 principal components scores values for ~10% of the cell locations within the Landsat 8 image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Visualize the PCA convolution raster surfaces (Figure 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_rs.plot(x='x',y='y',col='band',col_wrap=3,figsize=(15,conv_rs.nbands),robust=True,cmap='PRGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 5.__ Independent component surfaces (ICSs) derived from a principal component analysis of values taken from a systematic sample of cell locations within a subset of a Landsat scene for a kernel size of five by five cells. The first eleven ICSs account for a more than 95% of the variance within the data.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "### In this notebook we have demonstrated how to use sampling, convolution kernels, and PCA to project multi-band raster data into independent component space (Figure 4) that highlights various orthogonal aspects of the input data while simultaneously reducing the dimensionality of the data. The results of our analysis emphasize both hue and textural aspects of the data within each principal component that can also be viewed as a series of convolution kernel weights. While kernel cell weights provide unique insights into the linear relationships among image bands and neighbor cell values, when combined with Raster Tools processing architecture they can be used to produce ICSs (Figure 5) that spatially emphasize independent hue and textural aspects of the input data. \n",
    "### For example, the first ICS in Figure 5 highlights a hue change across spectral bands that emphasizes bright to dark cell values within the image. The kernel weights for the first component (Display 1) verify this assertion with all positive values that generally share importance equally across all band kernels and cell values. When compared against second component ICS (Figure 5), it is clear that this component emphasizes the differences between color and infrared band values while also highlighting an edge effect of neighboring pixel values (Display 1). Investigating the weights of each kernel for each component can provide insights to the relative amounts of information (variation) within the data across both raster bands and neighboring cell space. \n",
    "\n",
    "### Additionally, projecting band and neighboring cell values into orthogonal space provides a straightforward way to maintain as much information as possible within the data while simultaneously reducing the duplicated aspects of the data (Figure 3). In our example we ordered each component based on the amount of variation explained in the data for that component and used a threshold of 95% of the total variation in the data to determine the number of ICSs to create. Depending on the question at hand, analyst may want to pick and choose which components have relevance to the phenomenon of interest. Once decided and projected, ICSs can be used as potential predictor variables in downstream analyses. Additionally, kernel weights could be used as potential kernel cell starting values in deep learning convolution neural networks to aid in solving for optimal kernel cell weights given a set of labels. \n",
    "\n",
    "### Although the objective in this example was to linear project the raster data across both image bands and neighboring cell values in a way that reduces the dimensionality of the data and determine a set of kernel weights used to produce ICSs, one could easily apply this same type of approach to optimize kernel cell weights for regression and classification. The primary difference in this case is that a regression or classification methodology along with training response values would be used to optimally determine kernel cell weights as opposed to using a PCA to determine kernel cell values. In the case of optimizing kernel cell weights for regression or classification, ICSs surface could also be inputs to the process. Regardless of intended use, our described approach provides an optimal solution that linearly describes unique hue and textural aspects of the data across both raster band channels and neighboring cell values while simultaneously reducing the dimensionality of the data, making it ideal for downstream regression and classification analysis.                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA-fofzdw_70"
   },
   "source": [
    "## Conclusion\n",
    "### This approach to estimating weights for each convolution kernel and then using those weights to convolve an image (raster stack) highlights various features in the image, is quick, and mathematically determines kernel weights such that each band in the output convolved image is independent of the other bands values. Moreover, the process removes all redundant information across bands and within kernel cell values, which is also desirable. These surfaces should make for effective predictor variables and should make it easy to spread and balance a sample across all the information in a convolved image.    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rstools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

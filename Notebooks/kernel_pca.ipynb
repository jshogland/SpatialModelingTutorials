{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/kernel_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcZNhvYmw_7v"
      },
      "source": [
        "# Estimating kernel weights using PCA and a defined analysis window\n",
        "## In this notebook we will explore the use of Raster Tools and Scikit learn functions to project predictor surfaces into orthogonal space for modeling. A few key objectives of using this approach:\n",
        "- Determine and use the optimal cell weights of a convolution kernel (user defined size) that can be used to transform a given raster and its bands into a subset of surfaces that explain a user specified amount of the variation in the image data.\n",
        "- Efficiently create orthogonal predictor surfaces that account for band and spatial covariation.\n",
        "- Create predictor surfaces that highlight various hue and textural attributes within the data.\n",
        "### The approach\n",
        "- Use sampling to create training sets\n",
        "- Scale input rasters to unit variance\n",
        "- Perform PCA on scaled training sets that include all input cell values for the cells within a user specified analysis window\n",
        "- Center scaled cell values, multiply PCA score weights by centered values, and sum values within the analysis window to perform the convolution\n",
        "- Optionally, rescale PCA transformed values to a specified bit depth for storage and downstream analyses\n",
        "\n",
        "John Hogland 12/6/2024\n",
        "\n",
        "#### Study area for this example includes portions of the Custer Gallatin Nation Forest\n",
        "\n",
        "Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4_t0-07xMKD"
      },
      "outputs": [],
      "source": [
        "!pip install mapclassify\n",
        "!pip install osmnx\n",
        "!pip install raster_tools\n",
        "!pip install planetary-computer\n",
        "!pip install pystac-client\n",
        "!pip install stackstac\n",
        "!pip install pygeohydro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5s6NvQ3xbTe"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uuRURE7w_7w"
      },
      "outputs": [],
      "source": [
        "import numpy as np, os, geopandas as gpd, pandas as pd, osmnx as ox, pystac_client, planetary_computer, stackstac\n",
        "from raster_tools import Raster, raster, general, focal, zonal\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UlvE6_yHioO"
      },
      "source": [
        "## Introduction\n",
        "### Multispectral remotely sensed datasets are commonly used as predictor variables in many classification, regression, and clustering models. Often these data are highly correlated and covary across bands and x and y space. For compression, storage, and predictive modeling purposes it is often advantageous to project those data along shared axes of covariance to create independent transformed variables using principal component anlaysis (PCA).\n",
        "### In this example we explore the use of a PCA to project multispectral imagery along orthogonal axes derived from both band and neighboring cell values. Our procedure automates the selection of optimal kernel weights for multidimensional convolution kernels based on principal component scores and the proportion of the variation (information) explained by each component."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzrUU7gnw_7x"
      },
      "source": [
        "### The study area\n",
        "#### Get the boundary data for portions of the Custer Gallatin National Forest and create a interactive location map of the study (Figure 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdV_EZQgw_7x"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "#use OpenStreetMaps to get the boundary of the NF\n",
        "nf=ox.geocode_to_gdf('Custer Gallatin National Forest, MT, USA')\n",
        "\n",
        "#get first polygon of the NF\n",
        "nfe=nf.explode()\n",
        "nf1=gpd.GeoSeries(nfe.geometry.iloc[10],crs=nf.crs)\n",
        "\n",
        "#project to Albers equal area\n",
        "nf1p=nf1.to_crs(5070)\n",
        "\n",
        "#Visualize the nf1 and sample locations\n",
        "m=nf1p.explore(color='red',style_kwds=dict(fill=False,weight=5))\n",
        "folium.TileLayer(\n",
        "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
        "    attr=\"Esri\",\n",
        "    name=\"Esri Imagery\",\n",
        "    overlay=False,\n",
        "    control=True,\n",
        ").add_to(m)\n",
        "folium.LayerControl().add_to(m)\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLXabmv_HioP"
      },
      "source": [
        "__Figure 1.__ Interactive location map of the study area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH8N_5_THioQ"
      },
      "source": [
        "## Methods\n",
        "### To project Landsat 8 imagery to independent component surfaces (ICSs) we will implement a multistep approach.\n",
        "1. Download part of a Landsat scene for the area around the Custer Gallatin Nation Forest (Figure 1) from Planetary Computer.\n",
        "2. Create convolution PCA model using a ksize by ksize analysis window.\n",
        "ksize. Apply component scores to kernel cell values within each Landsat band.\n",
        "\n",
        "To perform these steps, we created a series of python functions that utilize Scikit Learn and Raster Tools application programming interface (API).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU3LLnKsw_7x"
      },
      "source": [
        "### Step 1: Get Landsat 8 Imagery\n",
        "Create download definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FvPl1L4w_7x"
      },
      "outputs": [],
      "source": [
        "#create definition to mosaic stac data\n",
        "def mosaic_stac(xr):\n",
        "    return stackstac.mosaic(xr)\n",
        "\n",
        "#create definition to extract stac data\n",
        "def get_stac_data(geo,url=\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"sentinel-2-l2a\",res=30,crs=5070,**kwarg):\n",
        "    '''\n",
        "    gets tiled data from planetary computer as a dask backed xarray that intersects the geometry of the point, line, or polygon\n",
        "\n",
        "    geo = (polygon) geometry bounding box (WGS84)\n",
        "    url = (string) base url to planetary computer https://planetarycomputer.microsoft.com/api/stac/v1\n",
        "    name = (string) catelog resource\n",
        "    qry =  (dictionary) of property values {'eo:cloud_cover':{'lt':1}}\n",
        "    res = (tuple of numbers) output resolution (x,y)\n",
        "    crs = (int) output crs\n",
        "    dt = (string) data time intervale e.g., one month: 2023-06, range: 2023-06-02/2023-06-17\n",
        "    limit = (int) max number of items to return\n",
        "\n",
        "    returns (xarray data array and stac item catalog)\n",
        "    '''\n",
        "    catalog = pystac_client.Client.open(url, modifier=planetary_computer.sign_inplace)\n",
        "    srch = catalog.search(collections=name, intersects=geo, **kwarg)\n",
        "    ic = srch.item_collection()\n",
        "    if(len(ic.items)>0):\n",
        "        xra = stackstac.stack(ic,resolution=res,epsg=crs)\n",
        "        xra = mosaic_stac(xra)\n",
        "    else:\n",
        "        xra=None\n",
        "\n",
        "    return xra,ic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lORu4UOw_7y"
      },
      "source": [
        "Download the data and create a raster object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIS1S--Fw_7y"
      },
      "outputs": [],
      "source": [
        "#get stac data landsat data\n",
        "if(not os.path.exists('ls82016.tif')):\n",
        "    xmin,ymin,xmax,ymax=nf1p.buffer(200).total_bounds\n",
        "    ls30, ic =get_stac_data(nf1.geometry[0],\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"landsat-c2-l2\",res=30,crs=5070,datetime='2016-06-15/2016-06-30',query={'eo:cloud_cover':{'lt':10},'platform':{'eq':'landsat-8'}},limit=1000)\n",
        "    ls30s=Raster(ls30.sel(band=['red', 'green', 'blue','nir08', 'lwir11','swir16', 'swir22'],x=slice(xmin,xmax),y=slice(ymax,ymin)))\n",
        "    ls30s=ls30s.save('ls82016.tif')\n",
        "\n",
        "ls30s=Raster('ls82016.tif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSnEqLbbw_7z"
      },
      "source": [
        "### Visualize the boundary and  imagery (Figure 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou2DtwCOHioQ"
      },
      "outputs": [],
      "source": [
        "p=nf1p.plot(edgecolor='red',facecolor='none',figsize=(15,10),linewidth=5)\n",
        "p=ls30s.get_bands([1,2,3]).xdata.plot.imshow(ax=p,robust=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qhutDroHioQ"
      },
      "source": [
        "__Figure 2.__ Overlay of Landsat 8 image subset (RGB bands) and the study area boundary outline in red."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uK7owb-w_7z"
      },
      "source": [
        "### Step 2: Create convolution PCA model\n",
        "Create definitions to sample the data, generate weights, and perform convolution analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1ZotYGhw_7z"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numba as nb\n",
        "import xarray as xr\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _conv_pca(x,cmp_, m_, size):\n",
        "    '''\n",
        "    Performs the convolution given a array, component scores, means, and kernel size using dask's map_overlap function\n",
        "    x=(numpy array) of data\n",
        "    cmp_= (numpy array) component scores from sklearn PCA procedure\n",
        "    m_= (numpy array) mean values from sklearn PCA procedure\n",
        "    size= (int) width of the kernel\n",
        "\n",
        "    returns a numpy array of correct shape for PCA transformation\n",
        "    '''\n",
        "    bnd,rws,clms=x.shape\n",
        "    hs=int(size/2)\n",
        "    outarr=np.empty((cmp_.shape[0],rws,clms))\n",
        "    for ri in range(hs,rws-hs):\n",
        "        sr=ri-hs\n",
        "        for ci in range(hs,clms-hs):\n",
        "            sc=ci-hs\n",
        "            vls=x[:,sr:sr+size,sc:sc+size].flatten()\n",
        "            for b in range(cmp_.shape[0]):\n",
        "                vls2=((vls-m_)*cmp_[b,:]).sum() #removed the centering piece in standard scaler it is done here\n",
        "                outarr[b,ri,ci]=vls2\n",
        "\n",
        "    return outarr\n",
        "\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _expand_pnts_for_kernel(isys,isxs,wsize):\n",
        "    '''\n",
        "    Extracts values for kernel cells. Cells indices falling on the boundary of the image are moved in one index value.\n",
        "    isys=array of row index locations\n",
        "    isxs=array of column index locations\n",
        "    wsize=width of the kernel\n",
        "\n",
        "    returns two new lists of index values kernel cell locations that can be used to extract coordinate from an xarray data array\n",
        "    '''\n",
        "    hw=int(wsize/2)\n",
        "    isys2=np.zeros(isys.shape[0]*wsize*wsize,dtype='int32')\n",
        "    isxs2=np.zeros(isxs.shape[0]*wsize*wsize,dtype='int32')\n",
        "    cnt=0\n",
        "    for r in range(isys.shape[0]):\n",
        "        rvl=isys[r]\n",
        "        cvl=isxs[r]\n",
        "        rvlm=rvl-hw\n",
        "        for r2 in range(wsize):\n",
        "            nr=rvlm+r2\n",
        "            cvlm=cvl-hw\n",
        "            for c2 in range(wsize):\n",
        "                nc=cvlm+c2\n",
        "                isys2[cnt]=nr\n",
        "                isxs2[cnt]=nc\n",
        "                cnt+=1\n",
        "\n",
        "    return isys2,isxs2\n",
        "\n",
        "\n",
        "def _sys_sample_image(rs,p,wsize=1):\n",
        "    '''\n",
        "    Creates a systematic sample of an image given a percent of cells sampled.\n",
        "    rs = Raster object to be sampled\n",
        "    p = percent of pixels to sample\n",
        "    wsize=(int) width of a square kernel in cells if using convolution type analyses\n",
        "\n",
        "    returns a 2d array of cell values rows=point centroid columns= band values\n",
        "    if using kernels columns correspond to kernel cell values for each point\n",
        "    '''\n",
        "    bnds,rws,clms=rs.shape\n",
        "    psq=np.sqrt(p)\n",
        "    sr=int(rws/(rws*psq))\n",
        "    sc=int(clms/(clms*psq))\n",
        "    rstr=int(np.random.rand()*sr)\n",
        "    rstc=int(np.random.rand()*sc)\n",
        "\n",
        "    isys=np.arange(rstr+wsize,rws-wsize,sr)\n",
        "    isxs=np.arange(rstc+wsize,clms-wsize,sc)\n",
        "    rws=isys.shape[0]\n",
        "    clms=isxs.shape[0]\n",
        "\n",
        "    isxs,isys=np.meshgrid(isxs,isys)\n",
        "    isxs=isxs.flatten()\n",
        "    isys=isys.flatten()\n",
        "\n",
        "    if(wsize>1):\n",
        "        isys,isxs=_expand_pnts_for_kernel(isys,isxs,wsize)\n",
        "\n",
        "    sel=rs.xdata.isel(x=xr.DataArray(isxs,dims='loc'),y=xr.DataArray(isys,dims='loc'))\n",
        "    vls=sel.values.reshape((sel.shape[0],rws*clms,wsize*wsize))\n",
        "    vls=np.moveaxis(vls,1,0).reshape(rws*clms,sel.shape[0]*wsize*wsize)\n",
        "\n",
        "    df=pd.DataFrame(vls)\n",
        "    vls=(df[df!=rs.null_value]).dropna().values\n",
        "\n",
        "    return vls\n",
        "\n",
        "def conv_pca(rs,prc=0.9,smp=0.01,ksize=0,output_bit_depth=None):\n",
        "    '''\n",
        "    determines convolution kernel weights for an optimal raster projection and returns a transformed raster\n",
        "    using those weights. Weights are derived from a PCA analysis of each kernel cell value. Kernel cell\n",
        "    values are extracted for each band in the rs stack.\n",
        "\n",
        "    rs=(Raster) input raster object\n",
        "    wsize=(int) window diameter for a square kernel measured in cells\n",
        "    prc=(float) the proportion of variation in the data kept in the final raster dataset (0-1)\n",
        "    smp=(float) the proportion of data used to build the transformation (training data - systematic random sample of location)\n",
        "    ksize=(int) kernel width to use measured in cells\n",
        "    output_bit_depths=(int) optional parameter used to scale the analysis outputs to a specified bit depth (e.g., 8,16,32).\n",
        "    By default (None) output values will not be scaled\n",
        "\n",
        "    returns a projected raster object and the pca object\n",
        "    '''\n",
        "    #scale values using a sample\n",
        "    vls=_sys_sample_image(rs,p=smp)\n",
        "    ss=StandardScaler(with_mean=False)\n",
        "    ss.fit(vls)\n",
        "\n",
        "    #apply the scaling to the input raster\n",
        "    ss_mdl = general.ModelPredictAdaptor(ss,'transform')\n",
        "    nch=(rs.nbands,*rs.xdata.chunks[1:])\n",
        "    sc_pred_rs=rs.model_predict(ss_mdl,rs.nbands).chunk(nch)\n",
        "\n",
        "    #perform pca using a sample of the scaled raster values\n",
        "    vls2=_sys_sample_image(sc_pred_rs,p=smp,wsize=ksize)\n",
        "\n",
        "    pca=PCA()\n",
        "    pca.fit(vls2)\n",
        "    #determine number of components to use\n",
        "    ev=pca.explained_variance_ratio_\n",
        "    sev=0\n",
        "    for i in range(ev.shape[0]):\n",
        "        e=ev[i]\n",
        "        sev+=e\n",
        "        if sev>prc:\n",
        "            break\n",
        "    kc=i+1 #add one to address 0 start\n",
        "\n",
        "    #extract component scores for _conv_pca method\n",
        "    kdf=pca.components_[0:kc,:] #scores,component (rows have weightings)\n",
        "    hw=int(ksize/2)\n",
        "\n",
        "    nch=sc_pred_rs.data.chunks\n",
        "    och=list(nch)\n",
        "    och[0]=(kc,)\n",
        "    och[1]=tuple(np.array(och[1])+hw*2)\n",
        "    och[2]=tuple(np.array(och[2])+hw*2)\n",
        "\n",
        "    #apply _conv_pca to map_overlap function\n",
        "    darr=sc_pred_rs.data.map_overlap(\n",
        "        _conv_pca,\n",
        "        depth={0: 0, 1: hw, 2: hw},\n",
        "        chunks=och,\n",
        "        boundary=np.nan,\n",
        "        dtype='f8',\n",
        "        meta=np.array((),dtype='f8'),\n",
        "        cmp_=kdf,\n",
        "        m_=pca.mean_,\n",
        "        size=ksize\n",
        "    )\n",
        "    #convert dask array back to a raster\n",
        "    cmp_rs=raster.data_to_raster(darr,x=sc_pred_rs.x,y=sc_pred_rs.y,affine=sc_pred_rs.affine,crs=sc_pred_rs.crs,nv=sc_pred_rs.null_value).chunk((1,*darr.chunks[1:]))\n",
        "\n",
        "    #scale projected raster to bit depth if specified\n",
        "    #mmsc=''\n",
        "    if(not output_bit_depth is None):\n",
        "        pcasvls=pca.transform(vls2)[:,0:kc]\n",
        "        l=pcasvls.min()\n",
        "        m=pcasvls.max()\n",
        "        cmp_rs=((cmp_rs-l)/(m-l)*(2**output_bit_depth-1))\n",
        "        cmp_rs=(cmp_rs.where(cmp_rs > 0,0).where(cmp_rs < 2**output_bit_depth,(2**output_bit_depth-1))).astype('int64')\n",
        "\n",
        "\n",
        "        # mmsc=MinMaxScaler()\n",
        "        # mmsc.fit(pcasvls)\n",
        "        # mmsc_mdl=general.ModelPredictAdaptor(mmsc,'transform')\n",
        "        # cmp_rs=(cmp_rs.model_predict(mmsc_mdl,cmp_rs.nbands)*(2**output_bit_depth-1)).astype('uint'+str(output_bit_depth))\n",
        "\n",
        "    return cmp_rs,pca\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClG52lIbHioR"
      },
      "source": [
        "### Step 3: Apply the convolution PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x40Sq2YHioR"
      },
      "outputs": [],
      "source": [
        "#perform the pca convolution process on the landsat image; kernel size 5 by 5, output bit depth 16.\n",
        "# This can be any size kernel. I have tried up to a 15 by 15.\n",
        "ksize=5\n",
        "conv_rs,pca=conv_pca(ls30s,prc=0.95,smp=0.1,ksize=ksize,output_bit_depth=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C3vu1IcHioR"
      },
      "source": [
        "## Results\n",
        "### Using our described approach, we accounted for 95% of the variation within the image using the first 10 principal components (Figure 3). Component convolution kernel weights (Display 1) highlight the linear relationships among both Landsat image bands and neighboring kernel cell values. For a random systematic sample of approximately 10% of the first 3 component values, unique clusters of information with varying trends appear in component space (Figure 4).\n",
        "### To transform our Landsat 8 image into 10 independent component surfaces (ICSs; Figure 5) required processing 70, 5 by 5 convolution kernels. T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr_NL1ggw_70"
      },
      "source": [
        "### - % variation explained in each band (component) of the transformed image (Figure 3).\n",
        "#### The number of bands correspond to the number of components that account for 95% of the variation in the 5 by 5 convolved image. Note that most of the variation/information in the data is explained in the first 3 components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8bYI_UXw_70"
      },
      "outputs": [],
      "source": [
        "var_exp=pd.DataFrame(pca.explained_variance_ratio_[:conv_rs.nbands])\n",
        "print('Total % variance explained in components =',var_exp.sum().values[0])\n",
        "p=var_exp.plot(kind='barh',title='Components by % Variation Explained', xlabel='% Variation', ylabel='Component', figsize=(15,8),legend=False).invert_yaxis()\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k42tuUq8HioR"
      },
      "source": [
        "__Figure 3.__ Proportion of variation explained in each principal component."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B27d1uE2HioR"
      },
      "source": [
        "### - Look at the kernel weights for each selected component (Display 1).\n",
        "#### Each component is made of the summation of 7 convolution kernels with the following weights. Convolution weights are applied to the centered and scaled input surface values of each band within the specified kernel of the input raster surface (ls30s in our example)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPrjnBllHioR"
      },
      "outputs": [],
      "source": [
        "kw=pca.components_[0:conv_rs.nbands,:]\n",
        "for k in range(kw.shape[0]):\n",
        "    krs=kw[k].reshape((ls30s.nbands,ksize,ksize))\n",
        "    print('\\nWeights for component',k)\n",
        "    for b in ls30s.band:\n",
        "        print('Band =',b)\n",
        "        print(pd.DataFrame(krs[b-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ6fROwUHioR"
      },
      "source": [
        "__Display 1.__ Kernel weights for each component of the PCA convolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-btl-7bHioR"
      },
      "source": [
        "### - Look at a 3d plot of the first 3 components for systematic random locations using 10% of the data. (Figure 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZV62m7lHioS"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "#get a sample of the PCA convolution raster values\n",
        "vls=_sys_sample_image(conv_rs,0.1,1)\n",
        "df=pd.DataFrame(vls)\n",
        "print('n =', df.shape[0])\n",
        "fig = px.scatter_3d(df, x=0, y=1, z=2\n",
        "              ,width=1500,height=800)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEQ_h8lWHioS"
      },
      "source": [
        "__Figure 4.__ A 3 dimensional representation of the first 3 principal components scores values for ~10% of the cell locations within the Landsat 8 image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cC7LskiHioS"
      },
      "source": [
        "### - Visualize the PCA convolution raster surfaces (Figure 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "106K-I_vHioS"
      },
      "outputs": [],
      "source": [
        "conv_rs.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0fGP4hYHioS"
      },
      "outputs": [],
      "source": [
        "conv_rs.plot(x='x',y='y',col='band',col_wrap=3,figsize=(15,conv_rs.nbands),robust=True,cmap='PRGn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcWYeVAdHioS"
      },
      "source": [
        "__Figure 5.__ Independent component surfaces (ICSs) derived from a principal component analysis of values taken from a systematic sample of cell locations within a subset of a Landsat scene for a kernel size of five by five cells. The first eleven ICSs account for a more than 95% of the variance within the data.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCUENoZcHioS"
      },
      "source": [
        "## Discussion\n",
        "### In this notebook we have demonstrated how to use sampling, analysis windows, and PCA to project multi-band raster data into independent component space (Figure 4) that highlights various orthogonal aspects of the input data while simultaneously reducing the dimensionality of the data. The results of our analysis emphasize both hue and textural aspects of the data within each principal components. While kernel cell weights provide unique insights into the linear relationships among image bands and neighbor cell values, when combined with Raster Tools processing architecture they can be used to produce ICSs (Figure 5) that spatially emphasize independent hue and textural aspects of the input data.                   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA-fofzdw_70"
      },
      "source": [
        "## Conclusion\n",
        "### The described approach is quick and mathematically determines kernel weights such that each band in the convolved output image is independent of the other band values. Moreover, the process removes all redundant information across bands and within kernel cell values, which is also desirable. These surfaces should make for effective predictor variables and\\or should make it easy to spread and balance a sample across all the hue and textural information within a defined analysis window, for a given raster dataset.    \n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7-gAu_0HioS"
      },
      "source": [
        "## Evaluate pca convolution predictors against the common texture for a 5 by 5 window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsHtODmyHioS"
      },
      "source": [
        "### Get Tree Canopy Cover and NLCD land cover for 2016 from MLRC website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKiKSLRfHioS"
      },
      "outputs": [],
      "source": [
        "import numpy as np, os, geopandas as gpd, pandas as pd, osmnx as ox, pystac_client, planetary_computer, stackstac\n",
        "from raster_tools import Raster, raster, general, focal, zonal\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pygeohydro as gh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY7tyiSZHioV"
      },
      "outputs": [],
      "source": [
        "outpath_lulc=\"lulc.tif\"\n",
        "outpath_tcc=\"tcc.tif\"\n",
        "\n",
        "if(not os.path.exists(outpath_lulc)):\n",
        "    bbox=nf1.envelope.buffer(0.001)\n",
        "\n",
        "    ds2016=gh.nlcd_bygeom(bbox,years={'cover':[2016],'canopy':[2016]},ssl=False)\n",
        "    lulc=Raster(ds2016[0].cover_2016).reproject(ls30s.geobox)\n",
        "    tcc=Raster(ds2016[0].canopy_2016).reproject(ls30s.geobox)\n",
        "    lulc.save(outpath_lulc)\n",
        "    tcc.save(outpath_tcc)\n",
        "\n",
        "lulc=Raster(outpath_lulc)\n",
        "tcc=Raster(outpath_tcc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fmfnNuVHioV"
      },
      "source": [
        "### GLCM\n",
        "- Create mean and standard deviation, GLCM texture surfaces (contrast, correlation; horizontal and vertical), and mean and standard deviation for edge convolution ([[0,1,0],[1,-4,1],[0,1,0]]) surfaces for the first 2 components\n",
        "- Create pca_convolution for the first two components\n",
        "- Create Random forest models and compare model results\n",
        "\n",
        "#### Create GLCM functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTdSNjU-HioW"
      },
      "outputs": [],
      "source": [
        "#GLCM\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _get_vl(img,glcm,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
        "    ovl=0\n",
        "    if(glcm=='contrast'):\n",
        "        ovl=_get_contrast(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    elif(glcm=='dissimilarity'):\n",
        "        ovl=_get_dissimilarity(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    elif(glcm=='homogeneity'):\n",
        "        ovl=_get_homogeneity(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    elif(glcm=='ASM'):\n",
        "        ovl=_get_asm(img,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
        "    elif(glcm=='energy'):\n",
        "        ovl=_get_energy(img,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
        "    elif(glcm=='entropy'):\n",
        "        ovl=_get_entropy(img,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
        "    elif(glcm=='correlation'):\n",
        "        ovl=_get_correlation(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    elif(glcm=='variance'):\n",
        "        ovl=_get_variance(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    elif(glcm=='std'):\n",
        "        ovl=_get_std(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    else:\n",
        "        ovl=_get_mean(img,rstart,rws,cstart,clms,roff,coff,n)\n",
        "    return ovl\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _get_contrast(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    s=0\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=img[r,c]\n",
        "            v2=img[r+roff,c+coff]\n",
        "            dif=v1-v2\n",
        "            vl= dif*dif*2\n",
        "            s+=vl\n",
        "    return s/n\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _get_mean(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    s=0\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=img[r,c]\n",
        "            v2=img[r+roff,c+coff]\n",
        "            vl=v1+v2\n",
        "            s+=vl\n",
        "    return s/n\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _get_dissimilarity(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    s=0\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=img[r,c]\n",
        "            v2=img[r+roff,c+coff]\n",
        "            vl=np.abs(v1-v2)*2\n",
        "            s+=vl\n",
        "    return s/n\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True, parallel=False)\n",
        "def _get_homogeneity(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    s=0\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=img[r,c]\n",
        "            v2=img[r+roff,c+coff]\n",
        "            dif=v1-v2\n",
        "            vl= 2/(1+(dif*dif))\n",
        "            s+=vl\n",
        "    return s/n\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_array(img,rstart,rws,cstart,clms,roff,coff,levels):\n",
        "    #dic={}\n",
        "    p_arr=np.zeros((levels,levels))\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=int(img[r,c])\n",
        "            v2=int(img[r+roff,c+coff])\n",
        "            p_arr[v1,v2]+=1\n",
        "            p_arr[v2,v1]+=1\n",
        "\n",
        "    return p_arr\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_entropy(img,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
        "    p = _get_array(img,rstart,rws,cstart,clms,roff,coff,levels)\n",
        "    rws2,clms2=p.shape\n",
        "    s=0\n",
        "    for r in range(rws2):\n",
        "        for c in range(clms2):\n",
        "            v=p[r,c]\n",
        "            vl=v/n+0.00000000001\n",
        "            s+=-1*vl*np.log(vl)\n",
        "\n",
        "    return s\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_asm(img,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
        "    p = _get_array(img,rstart,rws,cstart,clms,roff,coff,levels)\n",
        "    rws2,clms2=p.shape\n",
        "    s=0\n",
        "    for r in range(rws2):\n",
        "        for c in range(clms2):\n",
        "            v=p[r,c]\n",
        "            vl=v/n\n",
        "            s+=vl*vl\n",
        "\n",
        "    return s\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_energy(img,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
        "    return _get_asm(img,rstart,rws,cstart,clms,roff,coff,n,levels)**0.5\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_variance(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    s=0\n",
        "    s2=0\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=img[r,c]\n",
        "            v2=img[r+roff,c+coff]\n",
        "            s+=v1+v2\n",
        "            s2+=v1**2+v2**2\n",
        "    return (s2-((s**2)/n))/n\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_std(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    return _get_variance(img,rstart,rws,cstart,clms,roff,coff,n)**0.5\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_correlation(img,rstart,rws,cstart,clms,roff,coff,n):\n",
        "    sxy=0\n",
        "    sx=0\n",
        "    sx2=0\n",
        "\n",
        "    for r in range(rstart,rws):\n",
        "        for c in range(cstart,clms):\n",
        "            v1=img[r,c]\n",
        "            v2=img[r+roff,c+coff]\n",
        "            sx+=v1+v2\n",
        "            sx2+=v1**2+v2**2\n",
        "            sxy+=v1*v2\n",
        "\n",
        "\n",
        "    num=n*sxy*2-sx*sx\n",
        "    den=((n*sx2-sx**2)*(n*sx2-sx**2))**0.5\n",
        "\n",
        "    return num/den\n",
        "\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_n(rws,clms,dist,dir):\n",
        "    n=1\n",
        "    if(dir==0):\n",
        "        n=(rws-dist)*2*clms\n",
        "    elif(dir==2):\n",
        "        n=2*rws*(clms-dist)\n",
        "    else:\n",
        "        n=(rws-dist)*(clms-dist)*2\n",
        "    return n\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _get_glcm(img,glcms,dists,dirs,levels):\n",
        "    out_arr=np.zeros((len(glcms),len(dists),len(dirs)))\n",
        "    gcnt=0\n",
        "    for glcm in glcms:\n",
        "        dcnt=0\n",
        "        for dist in dists:\n",
        "            drcnt=0\n",
        "            for dir in dirs:\n",
        "                rws,clms=img.shape\n",
        "                n=_get_n(rws,clms,dist=dist,dir=dir)\n",
        "                # s=0\n",
        "                coff=0\n",
        "                roff=0\n",
        "                rstart=0\n",
        "                cstart=0\n",
        "                if(dir==0):\n",
        "                    coff=dist\n",
        "                    clms=clms-coff\n",
        "                elif(dir==1):\n",
        "                    coff=dist\n",
        "                    roff=dist\n",
        "                    clms=clms-coff\n",
        "                    rws=rws-roff\n",
        "                elif(dir==2):\n",
        "                    roff=dist\n",
        "                    rws=rws-roff\n",
        "                else:\n",
        "                    roff=(dist)\n",
        "                    coff=(-1*dist)\n",
        "                    cstart=dist\n",
        "                    rws=rws-roff\n",
        "                out_arr[gcnt,dcnt,drcnt]=_get_vl(img,glcm,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
        "                drcnt+=1\n",
        "            dcnt+=1\n",
        "        gcnt+=1\n",
        "    return out_arr\n",
        "\n",
        "@nb.jit(nopython=True, nogil=True,  parallel=False)\n",
        "def _glcm(X,glcms,dists,dirs,wsize,levels):\n",
        "    '''\n",
        "    Creates GLCM surfaces for a given array. Used with dask's map_overlap function.\n",
        "\n",
        "    X = (array) numpy array\n",
        "    glcms = (list of glcm names) ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation', 'mean', 'variance', 'std', 'entropy']\n",
        "    dists = (list of cell offsets) [1,2,3...]\n",
        "    dirs = (list of offset directions) [0,1,2,3] 0=horzontal, 1=diagonal 1, 2=vertical, 3=diagonal 2\n",
        "    wsize = (int) window width\n",
        "    returns a 3d array with dimensions equal to the length of bnds*glcms*dists*dirs,rows,columns of the original image and parameters\n",
        "    '''\n",
        "    bnd,rws,clms=X.shape\n",
        "    hw=int(wsize/2)\n",
        "    lg=len(glcms)\n",
        "    ld=len(dists)\n",
        "    ldr=len(dirs)\n",
        "    outarr=np.zeros((bnd*lg*ld*ldr,rws,clms))\n",
        "    for b in range(bnd):\n",
        "        bndst=b*lg*ld*ldr\n",
        "        bndend=bndst+lg*ld*ldr\n",
        "        for r in range(0,rws-wsize):\n",
        "            nr=r+hw\n",
        "            for c in range(0,clms-wsize):\n",
        "                nc=c+hw\n",
        "                img= X[b,r:r+wsize,c:c+wsize]\n",
        "                vls=_get_glcm(img,glcms,dists,dirs,levels)\n",
        "                outarr[bndst:bndend,nr,nc]=vls.flatten()\n",
        "    return outarr\n",
        "\n",
        "def glcm_wd(rs,glcm='contrast',dist=1,dir=0,wsize=3,cat=8):\n",
        "    '''\n",
        "    Creates GLCM Raster for a specified GLCM and window size.\n",
        "\n",
        "    rs = (Raster) input raster\n",
        "    glcm = (string) glcm names ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation', 'mean', 'variance', 'std', 'entropy']\n",
        "    dist = (int) cell offsets) 1,2,3, or ...\n",
        "    dir = (int) offset directions) 0,1,2, or 3 0=horzontal, 1=diagonal 1, 2=vertical, 3=diagonal 2\n",
        "    wsize = (int) window width\n",
        "    cat = (int) optional values for ASM, energy, and entropy GLCM. For these GLCM metrics, raster cell values cannot be greater than the number of levels-1\n",
        "\n",
        "    returns a mutiband Raster with dimensions equal to the length of bnds*glcms*dists*dirs,rows,columns of the original image and parameters\n",
        "    '''\n",
        "    hw=int(wsize/2)\n",
        "    #use map overlap function to retrieve kernel cell values\n",
        "    darr = rs.data.map_overlap(\n",
        "        _glcm,\n",
        "        depth={0: 0, 1: hw, 2: hw},\n",
        "        trim=True,\n",
        "        boundary=0,\n",
        "        dtype='f8',\n",
        "        meta=np.array((),dtype='f8'),\n",
        "        glcms=[glcm],\n",
        "        dists=[dist],\n",
        "        dirs=[dir],\n",
        "        wsize=wsize,\n",
        "        levels=cat,\n",
        "    )\n",
        "    out_rs=raster.data_to_raster(darr,mask=rs.mask,x=rs.x,y=rs.y,affine=rs.affine,crs=rs.crs)\n",
        "    return out_rs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxg8-GrMHioW"
      },
      "source": [
        "#### Create predictors for common texture metrics (5 by 5 window) and pca_conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkshZfCYHioW"
      },
      "outputs": [],
      "source": [
        "outpath_com='com_pred.tif'\n",
        "outpath_pca='pca_pred.tif'\n",
        "ksize=5\n",
        "red_nir = ls30s.get_bands([1,4])\n",
        "\n",
        "if(not os.path.exists(outpath_com)):\n",
        "    fm=focal.focal(red_nir,'mean',ksize,ksize)\n",
        "    fs=focal.focal(red_nir,'std',ksize,ksize)\n",
        "    edg=focal.convolve(red_nir,[[0,1,0],[1,-4,1],[0,1,0]])\n",
        "    em=focal.focal(edg,'mean',ksize,ksize)\n",
        "    es=focal.focal(edg,'std',ksize,ksize)\n",
        "    gcont_h=glcm_wd(red_nir,'contrast',1,0,wsize=ksize)\n",
        "    gcont_v=glcm_wd(red_nir,'contrast',1,2,wsize=ksize)\n",
        "    gcorr_h=glcm_wd(red_nir,'correlation',1,0,wsize=ksize)\n",
        "    gcorr_v=glcm_wd(red_nir,'correlation',1,2,wsize=ksize)\n",
        "\n",
        "    t_pred_rs=general.band_concat([fm,fs,gcont_h,gcont_v,gcorr_h,gcorr_v,em,es])\n",
        "\n",
        "\n",
        "    t_pred_rs.save(outpath_com)\n",
        "\n",
        "\n",
        "t_pred_rs=Raster(outpath_com)\n",
        "\n",
        "if(not os.path.exists(outpath_pca)):\n",
        "    pca_pred_rs,pca=conv_pca(red_nir,0.95,0.1,ksize)\n",
        "    pca_pred_rs.save(outpath_pca)\n",
        "\n",
        "pca_pred_rs=Raster(outpath_pca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esmv25DwHioW"
      },
      "source": [
        "### Create Random Forest Models\n",
        "#### Perform 100 iteration of the analysis using a sample size of 150 and look at accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYJHrGorHioW"
      },
      "outputs": [],
      "source": [
        "def get_tbl(xs,ys,rs):\n",
        "    sel=rs.xdata.sel(x=xr.DataArray(xs,dims='loc'),y=xr.DataArray(ys,dims='loc'),method=\"nearest\")\n",
        "    vls=sel.values\n",
        "    vls=np.moveaxis(vls,1,0)\n",
        "    df=pd.DataFrame(vls)\n",
        "    vls=(df[df!=rs.null_value]).dropna().values\n",
        "    return vls\n",
        "\n",
        "def get_smp(bndry,rs,ss=150,ksize=5):\n",
        "    pbnd=bndry.to_crs(rs.crs)\n",
        "    bnd=pbnd.unary_union\n",
        "    area=bnd.area\n",
        "    sk=int(((area/ss) ** 0.5)/rs.resolution[0])\n",
        "    x=rs.x[ksize:-ksize]\n",
        "    y=rs.y[ksize:-ksize]\n",
        "    np.random.seed(0)\n",
        "    xst=np.random.randint(sk)\n",
        "    yst=np.random.randint(sk)\n",
        "    xs=x[xst:x.shape[0]:sk]\n",
        "    ys=y[yst:y.shape[0]:sk]\n",
        "    xs,ys=np.meshgrid(xs,ys)\n",
        "    xs=xs.flatten()\n",
        "    ys=ys.flatten()\n",
        "    pnts=gpd.points_from_xy(xs,ys)\n",
        "    pnts=pnts[pnts.intersects(bnd)]\n",
        "\n",
        "    return pnts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "655qdwTXHioW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "ss=1500\n",
        "tss=int(ss*0.75)\n",
        "vss=int(ss-tss)\n",
        "\n",
        "iter=100\n",
        "ac1=[]\n",
        "ac2=[]\n",
        "ac3=[]\n",
        "ac4=[]\n",
        "n1=[]\n",
        "n2=[]\n",
        "\n",
        "pnts=get_smp(nf1p,lulc,ss,ksize)\n",
        "xs = pnts.x\n",
        "ys = pnts.y\n",
        "pred_tbl=get_tbl(xs,ys,t_pred_rs)\n",
        "pred_tbl2=get_tbl(xs,ys,pca_pred_rs)\n",
        "rsp_tbl=get_tbl(xs,ys,general.band_concat([lulc,tcc]))\n",
        "\n",
        "for i in range(iter):\n",
        "\n",
        "    cls = RandomForestClassifier(max_samples=0.66,random_state=0)\n",
        "    cls2 = RandomForestClassifier(max_samples=0.66,random_state=0)\n",
        "    reg = RandomForestRegressor(max_samples=0.66,random_state=0)\n",
        "    reg2 = RandomForestRegressor(max_samples=0.66,random_state=0)\n",
        "\n",
        "    rng=np.arange(ss)\n",
        "    ind=np.random.choice(rng,tss,False)\n",
        "    ind2=rng[~np.isin(rng,ind)]\n",
        "    X=pred_tbl[ind,:]\n",
        "    X2=pred_tbl2[ind,:]\n",
        "    yc=rsp_tbl[ind,0]\n",
        "    yr=rsp_tbl[ind,1]\n",
        "    reg.fit(X,yr)\n",
        "    reg2.fit(X2,yr)\n",
        "    cls.fit(X,yc)\n",
        "    cls2.fit(X2,yc)\n",
        "\n",
        "    pred=reg.predict(pred_tbl)\n",
        "    pred2=reg2.predict(pred_tbl2)\n",
        "    pred3=cls.predict(pred_tbl)\n",
        "    pred4=cls2.predict(pred_tbl2)\n",
        "\n",
        "    ac1.append((rsp_tbl[ind2,0]==pred3[ind2]).sum()/ind2.shape[0])\n",
        "    ac2.append((rsp_tbl[ind2,0]==pred4[ind2]).sum()/ind2.shape[0])\n",
        "    ac3.append(np.mean((rsp_tbl[ind2,1]-pred[ind2])**2)**0.5)\n",
        "    ac4.append(np.mean((rsp_tbl[ind2,1]-pred2[ind2])**2)**0.5)\n",
        "    n1.append(pred_tbl.shape[1])\n",
        "    n2.append(pred_tbl2.shape[1])\n",
        "\n",
        "print('Classification Common and pca texture metrics:',np.mean(ac1),np.mean(ac2))\n",
        "print('Classification SE of common pca texture metrics:',np.std(ac1),np.std(ac2))\n",
        "print('Regression Common and pca texture metrics:',np.mean(ac3),np.mean(ac4))\n",
        "print('Regression SE of common pca texture metrics:',np.std(ac3),np.std(ac4))\n",
        "print('\\nNumber of predictors for common texture model =',np.mean(n1))\n",
        "print('\\nNumber of predictors for pca texture model =',np.mean(n2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9iIzXFaHioW"
      },
      "outputs": [],
      "source": [
        "sdf=pd.DataFrame([ac1,ac2],index=['common_class','pca_class'])\n",
        "sdf=sdf.T\n",
        "sdf.boxplot(figsize=(8,5))\n",
        "display(sdf.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu8PI-sSHioX"
      },
      "outputs": [],
      "source": [
        "sdf2=pd.DataFrame([ac3,ac4],index=['common_reg','pca_reg'])\n",
        "sdf2=sdf2.T\n",
        "sdf2.boxplot(figsize=(8,5))\n",
        "display(sdf2.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33HRA3sSHioX"
      },
      "source": [
        "### Discussion\n",
        "#### There was no statistical difference in model accuracy between random forest models derived from common texture metrics and models built using the newly described convolution PCA approach. However, the PCA methodology used 5 fewer predictor with the same accuracy. Moreover, the convolution PCA methodology provides an automated texture approach as opposed to using multiple convolution kernels and GLCMs.    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "rstools",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

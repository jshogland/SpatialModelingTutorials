{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/Umatilla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87b80a3-41da-4bd6-bb2a-1b1816017ec5",
      "metadata": {
        "id": "e87b80a3-41da-4bd6-bb2a-1b1816017ec5"
      },
      "source": [
        "# Umatilla Fire Resilience\n",
        "\n",
        "#### This notebook demonstrates how Raster Tools and ancillary data can be used to identify and quantify treatment locations and cost of implementation to reduce fire risk and create fire resilient landscapes. Datasets used in this notebook include raster surfaces created in [Riley et al. 2022](https://www.fs.usda.gov/rds/archive/catalog/RDS-2025-0031), roads, streams, water bodies, sawmill locations, [potential operational delineations (PODs)](https://www.fs.usda.gov/research/rmrs/projects/pods), and a digital elevation model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cef10288-a19a-4c3b-aad2-d7703dc91e92",
      "metadata": {
        "id": "cef10288-a19a-4c3b-aad2-d7703dc91e92"
      },
      "source": [
        "#### Author: John Hogland 4/05/2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e61784a-5f88-4626-afe3-5832f4d05b2b",
      "metadata": {
        "id": "6e61784a-5f88-4626-afe3-5832f4d05b2b"
      },
      "source": [
        "## Overview\n",
        "#### Using various data sources we will estimate the potential biomass removals and costs associated with transforming the Umatilla National Forest into a more fire resilient landscape. To help navigate these steps the notebook has been split into five sections:\n",
        "1. Installing software\n",
        "2. Downloading the data\n",
        "3. Linking summarized FIA data with tree lists\n",
        "4. Defining Desired Future Conditions for a fire resilient landscape\n",
        "5. Quantifying potential costs\n",
        "6. Linking potential costs with potential removals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a652891-0576-4571-9669-6951accee535",
      "metadata": {
        "id": "4a652891-0576-4571-9669-6951accee535"
      },
      "source": [
        "#### Step 1: Installing software\n",
        "##### This step is meant to install Raster Tools and upgrade various packages on [Google's Colab](https://colab.research.google.com/). If working locally and raster tools has already been installed, this step can be skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0dc3a32-6869-4b5d-a797-b4d7a17658a7",
      "metadata": {
        "id": "f0dc3a32-6869-4b5d-a797-b4d7a17658a7"
      },
      "outputs": [],
      "source": [
        "!pip install mapclassify\n",
        "!pip install osmnx\n",
        "!pip install py3dep==0.17.1\n",
        "!pip install raster_tools\n",
        "!pip install distributed --upgrade\n",
        "!pip install rapids --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d7a8369-c355-4c3a-ba7d-ed98a5a62e0c",
      "metadata": {
        "id": "8d7a8369-c355-4c3a-ba7d-ed98a5a62e0c"
      },
      "outputs": [],
      "source": [
        "from raster_tools import Raster, distance, general, Vector, clipping, surface, creation\n",
        "import numpy as np, geopandas as gpd, pandas as pd, osmnx as ox, py3dep\n",
        "import gdown, zipfile, os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "526e0022",
      "metadata": {
        "id": "526e0022"
      },
      "outputs": [],
      "source": [
        "# Get Tree List Data\n",
        "#2022 data\n",
        "url='https://usfs-public.box.com/shared/static/c4pv6jamvxjdbzgezztvs43bqudigwaq.zip'#'https://usfs-public.box.com/shared/static/yz7h8b8v92scoqfwukjyulokaevzo6v6.zip'#Old link: https://s3-us-west-2.amazonaws.com/fs.usda.rds/RDS-2021-0074/RDS-2021-0074_Data.zip'\n",
        "\n",
        "\n",
        "outfl = r\"tree_list_data.zip\"\n",
        "\n",
        "if not os.path.exists(outfl):\n",
        "    gdown.download(url=url, output=outfl, quiet=False, fuzzy=True)\n",
        "\n",
        "    with zipfile.ZipFile(outfl, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d35cd673-e348-4774-85fd-55a12ef3659f",
      "metadata": {
        "id": "d35cd673-e348-4774-85fd-55a12ef3659f"
      },
      "source": [
        "#### Step 2: Download the data\n",
        "We will be using 3 main sources of data for this notebook; the Forest Service Research Data Archive, the Open Street Maps (OSM) project, and USGS 3DEP program. To download the tree data for this notebook run the cell Get Tree list data. After downloading the tree list data and extracting the zipped contents you will have a \".\\data\" directory containing the raster surfaces created within the [Riley 2022](https://www.fs.usda.gov/rds/archive/catalog/RDS-2025-0031) study and supporting crosswalk and tree list tables. While the tree list data covers all of Conus USA, we only need the boundary of the Umatilla's National Forest for our example. Using the Umatilla National Forest boundary extent, we will subset returned polygons from the tree list data and download roads, streams, sawmills, and elevation data. For roads, streams, and sawmill locations we will leverage the Open Street Maps (OSM) project. To download OSM vector datasets run the Get OSM data cell. For elevation data we will download National Elevation Dataset (NED) 30 m DEMs from USGS 3DEP project. To download elevation data run the Get DEM data cell. Finally, to download potential operational delineations, we will extract the polygon POD boundaries from the [National PODs feature service](https://services3.arcgis.com/T4QMspbfLg3qTGWY/arcgis/rest/services/Nat_PODs_Public/FeatureServer).   \n",
        "\n",
        "#### Files we will be using in this notebook include:\n",
        "- national_2022_tree_list = tree list raster\n",
        "- TL_CN_Lookup = look up table matching TID numbers with Raster values\n",
        "- Tree_table_Conus = Tree tables in Text format\n",
        "- OSM roads\n",
        "- OSM streams\n",
        "- OSM sawmills\n",
        "- 3DEP DEM\n",
        "- POD boundaries\n",
        "- FIA Species Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a788bc7-d70a-454f-8d05-0d9574b470a7",
      "metadata": {
        "id": "9a788bc7-d70a-454f-8d05-0d9574b470a7"
      },
      "outputs": [],
      "source": [
        "from shapely.geometry import box\n",
        "\n",
        "#Get OSM data\n",
        "national_forest=['Umatilla National Forest, OR']\n",
        "bnds=[]\n",
        "\n",
        "sawmill_address='600 NW Cedar St, Pilot Rock, OR 97868'\n",
        "lat_lon=[]\n",
        "bdist=0.1\n",
        "\n",
        "#get the boundary of the national forest from OSM and the location of sawmill\n",
        "if (len(national_forest)<1):\n",
        "    snf=gpd.GeoSeries(box(*bnds),crs='EPSG:4326')\n",
        "else:\n",
        "    snf=ox.geocode_to_gdf(national_forest).explode() #get each NF boundary as polygon\n",
        "    acres=snf.to_crs(5070).area * 0.000247105 # Calculate acres\n",
        "    snf['acres']=acres #assign acres to ploygons\n",
        "    ch=(acres > 500000) #find the Umatilla boundary based on acres\n",
        "    snf=snf.iloc[ch.values] #select the Umatilla boundary based on acres\n",
        "\n",
        "#get the location of the sawmill\n",
        "if(len(lat_lon)<2):\n",
        "    sawmill=ox.geocode_to_gdf(sawmill_address,which_result=1).centroid\n",
        "else:\n",
        "    sawmill=gpd.GeoSeries(gpd.points_from_xy(x=[lat_lon[1]],y=[lat_lon[0]],crs='EPSG:4326'))\n",
        "\n",
        "#Create a bounding box to download data\n",
        "ext=sawmill.union(snf.union_all())\n",
        "geo=box(*ext.total_bounds).buffer(bdist)\n",
        "\n",
        "#download road and stream data\n",
        "roads=ox.features_from_polygon(geo,{'highway':['motorway','trunk','primary','secondary','tertiary','unclassified','residential']})\n",
        "streams=ox.features_from_polygon(geo,{'waterway':['river','stream','cannel','ditch']})\n",
        "wbdy=ox.features_from_polygon(geo,{'water':['lake','reservoir','pond']})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400a084b-eed8-4790-a26f-c31a6a2e44dc",
      "metadata": {
        "id": "400a084b-eed8-4790-a26f-c31a6a2e44dc"
      },
      "outputs": [],
      "source": [
        "#Get 3Dep data\n",
        "dem=py3dep.get_dem(geo,resolution=30).expand_dims({'band':1})#add band dimension to the xarray dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a514e1-f3cd-4680-abfa-e40b5177249f",
      "metadata": {
        "id": "40a514e1-f3cd-4680-abfa-e40b5177249f"
      },
      "outputs": [],
      "source": [
        "#Get FIA Species Codes\n",
        "url='https://drive.google.com/file/d/1KBK3bpjgKDcpEeuylRo6zxwdSAtyuHCm/view?usp=sharing'\n",
        "outfl = r\"./STF_PODS_2020_V1.zip\"\n",
        "if(not os.path.exists(outfl)):\n",
        "    gdown.download(url=url, output=outfl, quiet=False, fuzzy=True)\n",
        "\n",
        "    with zipfile.ZipFile(outfl, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_uPmnwWbCvzi",
      "metadata": {
        "id": "_uPmnwWbCvzi"
      },
      "outputs": [],
      "source": [
        "#Get POD data\n",
        "import requests, shapely\n",
        "\n",
        "def get_pods(url, geo='',qry='1=1',layer=0):\n",
        "  '''\n",
        "  gets a geodataframe from a Feature Service given the url and optionally a bounding geometry and where clause\n",
        "\n",
        "  url=(string) base url for the feature service\n",
        "  geo=(object) a bounding box string, shapely polygon, geodataframe, or geoseries. string and shapely polygon objects are assumed to be in the same coordinate system as the feature service\n",
        "  qry=(string) where clause used to subset the data\n",
        "  layer= (int) the of the feature service to extract\n",
        "\n",
        "  return a geodataframe of features\n",
        "  '''\n",
        "  s_info=requests.get(url+'?f=pjson').json()\n",
        "  srn=s_info['spatialReference']['wkid']\n",
        "  sr='EPSG:'+str(srn)\n",
        "  if isinstance(geo,gpd.GeoDataFrame):\n",
        "    geo = (geo.to_crs(sr)).total_bounds\n",
        "  elif isinstance(geo,gpd.GeoSeries):\n",
        "    geo = (geo.to_crs(sr)).total_bounds\n",
        "  elif isinstance(geo,shapely.geometry.Polygon):\n",
        "    geo = geo.bounds\n",
        "  else:\n",
        "    pass\n",
        "  geo=','.join(np.array(geo).astype(str))\n",
        "  url1=url+'/'+str(layer)\n",
        "  l_info=requests.get(url1 + '?f=pjson').json()\n",
        "  maxrcn=l_info['maxRecordCount']\n",
        "  if maxrcn>100: maxrcn=100 #used to subset ids so query is not so long\n",
        "  url2 = url1+'/query?'\n",
        "  o_info=requests.get(url2,{'where': qry,'geometry':geo,'geometryType': 'esriGeometryEnvelope','returnIdsOnly':'True','f': 'pjson'}).json()\n",
        "  oid_name=o_info['objectIdFieldName']\n",
        "  oids=o_info['objectIds']\n",
        "  numrec=len(oids)\n",
        "  fslist = []\n",
        "  for i in range(0, numrec, maxrcn):\n",
        "    torec = i + (maxrcn-1)\n",
        "    if torec > numrec:\n",
        "      torec = numrec\n",
        "\n",
        "    objectIds = oids[i:torec]\n",
        "    idstr=oid_name + ' in (' + str(objectIds)[1:-1]+')'\n",
        "    prm={\n",
        "        'where': idstr,\n",
        "        'outFields': '*',\n",
        "        'returnGeometry': 'true',\n",
        "        'outSR':srn,\n",
        "        'f':'pgeojson',\n",
        "    }\n",
        "    ftrs=requests.get(url2,prm).json()['features']\n",
        "    fslist.append(gpd.GeoDataFrame.from_features(ftrs,crs=sr))\n",
        "\n",
        "  return gpd.pd.concat(fslist)\n",
        "\n",
        "\n",
        "\n",
        "url = r'https://services3.arcgis.com/T4QMspbfLg3qTGWY/arcgis/rest/services/Nat_PODs_Public/FeatureServer'\n",
        "pods=get_pods(url,gpd.GeoDataFrame(geometry=[geo],crs=snf.crs),layer=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606a2b4d-7c8e-4f24-a10d-2b698ec55cda",
      "metadata": {
        "id": "606a2b4d-7c8e-4f24-a10d-2b698ec55cda"
      },
      "outputs": [],
      "source": [
        "#Clip tree list data and project other datasets to the same projection as the tree list\n",
        "\n",
        "tlst=Raster('./Data/TreeMap2022_CONUS.tif')#'./Data/TreeMap2016.tif')\n",
        "\n",
        "snf_ply=snf.to_crs(tlst.crs)\n",
        "c_ply=gpd.GeoSeries([geo],crs=snf.crs).to_crs(tlst.crs)\n",
        "\n",
        "snf_tlst=clipping.clip(clipping.get_vector(c_ply),tlst)\n",
        "snf_roads=roads.to_crs(tlst.crs).reset_index()\n",
        "snf_streams=streams.to_crs(tlst.crs).reset_index()\n",
        "snf_wbdy=wbdy.to_crs(tlst.crs).reset_index()\n",
        "snf_sawmill=sawmill.to_crs(tlst.crs)\n",
        "snf_dem=Raster(dem.rio.reproject_match(snf_tlst.xdata))\n",
        "snf_pods=pods.to_crs(tlst.crs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab966c5-2c65-4f3d-877a-13ba0ea0f150",
      "metadata": {
        "id": "6ab966c5-2c65-4f3d-877a-13ba0ea0f150"
      },
      "outputs": [],
      "source": [
        "#visualize the projected data\n",
        "p1=snf_roads.plot(color='gray',figsize=(15,15),zorder=1)\n",
        "p2=snf_streams.plot(ax=p1, color='lightblue',zorder=2)\n",
        "p3=snf_wbdy.plot(ax=p2, color='lightblue',zorder=3)\n",
        "p4=(snf.to_crs(snf_tlst.crs)).plot(ax=p3,edgecolor='red',facecolor='none',linewidth=2,zorder=4)\n",
        "p5=snf_pods.plot(ax=p4, edgecolor='orange', facecolor='none',zorder=5)\n",
        "p6=snf_sawmill.plot(ax=p5, color = 'yellow',markersize=50,zorder=6)\n",
        "p7=snf_dem.plot(ax=p6,cmap='terrain',zorder=0)\n",
        "p7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b33acf-e879-418a-ae23-4cbadc8eab94",
      "metadata": {
        "id": "08b33acf-e879-418a-ae23-4cbadc8eab94"
      },
      "source": [
        "#### Step 3: Linking summarized FIA data with tree lists\n",
        "To link TreeMap2022_CONUS.tif raster surface to the summarized tree list values we will do the following:\n",
        "1. Filter TreeMap2022_CONUS_tree_table.csv to the TIDs of the clipped clipped TreeMap2022_CONUS.tif raster\n",
        "2. Summarize Tree_table by TIDs\n",
        "3. Reclassify TreeMap surface to summarized values\n",
        "4. Save out raster surfaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af89458",
      "metadata": {
        "id": "0af89458"
      },
      "outputs": [],
      "source": [
        "t_vls,t_cnt=np.unique(snf_tlst,return_counts=True)\n",
        "tree_tbl=pd.read_csv('./Data/TreeMap2022_CONUS_Tree_Table.csv',sep=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f9aeb7",
      "metadata": {
        "id": "86f9aeb7"
      },
      "outputs": [],
      "source": [
        "#subset data to values in raster\n",
        "tree_tbl_sub=tree_tbl[tree_tbl['TM_ID'].isin(t_vls)]\n",
        "rspc=pd.read_csv('REF_SPECIES_jen.csv',delimiter=',').dropna()\n",
        "usp=np.unique(tree_tbl_sub['SPCD'])\n",
        "rspc=rspc[rspc['SPCD'].isin(usp)]\n",
        "\n",
        "#Join Biomass equation coefficients with tree table\n",
        "tree_tbl_sub=tree_tbl_sub.merge(rspc,on='SPCD')\n",
        "\n",
        "#calculate basal area ft squared per acre (BAA)\n",
        "tree_tbl_sub['BAA']=(tree_tbl_sub['DIA']**2)*0.005454*tree_tbl_sub['TPA_UNADJ']\n",
        "\n",
        "#calculate pounds per acre (AGB)\n",
        "tree_tbl_sub['AGB']=(np.exp(tree_tbl_sub['JENKINS_TOTAL_B1'] + tree_tbl_sub['JENKINS_TOTAL_B2'] * np.log(tree_tbl_sub['DIA']*2.54))*2.2046)*tree_tbl_sub['TPA_UNADJ']#bone dry pounds per acre\n",
        "\n",
        "#calculate stem pounds per acre (SAGB)\n",
        "tree_tbl_sub['SAGB']=(np.exp(tree_tbl_sub['JENKINS_STEM_WOOD_RATIO_B1'] + tree_tbl_sub['JENKINS_STEM_WOOD_RATIO_B2'] / (tree_tbl_sub['DIA']*2.54)))*tree_tbl_sub['AGB']#bone dry pounds per acre\n",
        "\n",
        "#create needle (n) and broad (b) leaf groups (LTYPE)\n",
        "tree_tbl_sub['LTYPE']=np.where(tree_tbl_sub['SPCD']<300,\"n\",\"b\")\n",
        "\n",
        "#create regen vs merch groups\n",
        "tree_tbl_sub['MTYPE']=np.where(tree_tbl_sub['DIA']<5,'regen','merch')\n",
        "\n",
        "#split based on species code (live, dead)\n",
        "l_tree_tbl_sub = tree_tbl_sub[tree_tbl_sub['STATUSCD']==1]\n",
        "\n",
        "#summarize by plot and leaf type (LTYPE) and keep BAA TONS\n",
        "l_tree_sum=(l_tree_tbl_sub.groupby(['TM_ID','LTYPE','MTYPE']).sum())[['BAA','TPA_UNADJ','AGB','SAGB']]\n",
        "\n",
        "#calculate QMD\n",
        "l_tree_sum['QMD'] = ((l_tree_sum['BAA']/l_tree_sum['TPA_UNADJ'])/0.005454)**0.5\n",
        "\n",
        "#display the summarized table\n",
        "display(l_tree_sum)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7dc83a",
      "metadata": {
        "id": "3b7dc83a"
      },
      "outputs": [],
      "source": [
        "plot_nm=(l_tree_sum[(l_tree_sum.index.get_level_values('MTYPE')=='merch')&(l_tree_sum.index.get_level_values('LTYPE')=='n')]).reset_index(level=[1,2])\n",
        "plot_bm=(l_tree_sum[(l_tree_sum.index.get_level_values('MTYPE')=='merch')&(l_tree_sum.index.get_level_values('LTYPE')=='b')]).reset_index(level=[1,2])\n",
        "plot_nr=(l_tree_sum[(l_tree_sum.index.get_level_values('MTYPE')=='regen')&(l_tree_sum.index.get_level_values('LTYPE')=='n')]).reset_index(level=[1,2])\n",
        "plot_br=(l_tree_sum[(l_tree_sum.index.get_level_values('MTYPE')=='regen')&(l_tree_sum.index.get_level_values('LTYPE')=='b')]).reset_index(level=[1,2])\n",
        "rm_lst=[plot_nm,plot_bm,plot_nr,plot_br]\n",
        "at_lst=plot_nm.columns[-5:]\n",
        "\n",
        "print(at_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nw1S8D-zyKSC",
      "metadata": {
        "id": "Nw1S8D-zyKSC"
      },
      "outputs": [],
      "source": [
        "#Reclassify tree list raster to various BAA, TPA, AGB, SAGB, and QMD raster surfaces using summarized plot data\n",
        "rs_lst=[]\n",
        "for a in at_lst:\n",
        "    t_lst=[]\n",
        "    for r in rm_lst:\n",
        "        rs = snf_tlst.reclassify(r[a].astype('int32').to_dict(),unmapped_to_null=True)\n",
        "        t_lst.append(rs.where(~rs.to_null_mask(),0)) #set null values to zero and append raster to temp list\n",
        "    rs_lst.append(general.band_concat(t_lst))\n",
        "\n",
        "baa,tpa,agb,sagb,qmd=rs_lst #each raster is a 4 band surface with band estimates corresponding to needle leaf merch species, broadleaf  merch specie, needle leaf regen species, broad leaf regen species\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42368076-f14b-4e8e-9129-7937ff51ac0b",
      "metadata": {
        "id": "42368076-f14b-4e8e-9129-7937ff51ac0b"
      },
      "source": [
        "#### Step 4: Defining desired future condition (DFC)\n",
        "DFC are define based on spatial locations as described in **Table 1**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4b22493",
      "metadata": {
        "id": "b4b22493"
      },
      "source": [
        "<h4 style=\"text-align: Left;\">\n",
        "    <b>Table 1.</b> Criteria used to identify desired future condition (DFC).\n",
        "</h4>\n",
        "   \n",
        "|Feature|Characteristic|Threshold|Desired BAA|\n",
        "|:-:|:-:|:-:|:-:|\n",
        "|deferred|Area|NA|Existing BAA|\n",
        "|Water|Distance From|distance < 100 ft|Existing BAA|\n",
        "|Water|Distance From|distance > 100 ft|See Aspect Feature|\n",
        "|Elevation|Slope|slope < 50%|See Aspect Feature|\n",
        "|Elevation|Slope|slope > 50%|Existing BAA|\n",
        "|Elevation|Aspect|290<sup>o</sup><Aspect<360<sup>o</sup> or 0<sup>o</sup><Aspect<70<sup>o</sup> |85 ft<sup>2</sup> acre<sup>-1<sup/>|\n",
        "|Elevation|Aspect|70<sup>o</sup><Aspect<290<sup>o</sup>|65 ft<sup>2</sup> acre<sup>-1<sup/>|\n",
        "|PODs|Distance From|distance < 2000 ft | 20 ft<sup>2</sup> acre<sup>-1<sup/>|\n",
        "\n",
        "POD = potential wildland fire operations delineations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15fd039",
      "metadata": {
        "id": "a15fd039"
      },
      "outputs": [],
      "source": [
        "#summarize baa and convert baa (ft sqaured per acre)\n",
        "tbaa=general.local_stats(baa,'sum') #baa\n",
        "tton=(agb/2000)*0.222395 #tons per 30m cell\n",
        "ston=(sagb/2000)*0.222395 #tons per 30m cell\n",
        "\n",
        "#create distance surfaces for pods and water\n",
        "d_pods=distance.pa_proximity(Vector(snf_pods.boundary).to_raster(snf_dem))\n",
        "s_rs=Vector(snf_streams).to_raster(snf_dem)\n",
        "w_rs=Vector(snf_wbdy).to_raster(snf_dem)\n",
        "d_water=distance.pa_proximity(w_rs.where(~w_rs.to_null_mask(),s_rs))\n",
        "\n",
        "#create slope and aspect surfaces\n",
        "slp_rs=surface.slope(snf_dem,False)\n",
        "asp_rs=surface.aspect(snf_dem)\n",
        "\n",
        "#create dfc baa\n",
        "ach=((asp_rs<360) & (asp_rs>290)) | ((asp_rs<70) & (asp_rs>0))\n",
        "asp_baa=(ach * 85).where(ach,65)\n",
        "dch=d_pods<610 #2000 ft\n",
        "p_baa= asp_baa\n",
        "t1=p_baa.where((slp_rs<0.5),tbaa)\n",
        "t2=(dch*20).where(dch,t1)\n",
        "dfc=t2.where(d_water>30.48,tbaa) #100 ft\n",
        "\n",
        "#calc removals to meet DFC\n",
        "rem_rs = tbaa-dfc\n",
        "rem_rs = rem_rs.where((rem_rs > 0),0)\n",
        "\n",
        "#calc % removed Baa and estimate AGB removed to meet DFC (tons)\n",
        "pr_baa=rem_rs/tbaa\n",
        "ton_rm=general.local_stats(tton,'sum') * pr_baa\n",
        "ston_rm=general.local_stats(ston.get_bands([1,2]),'sum')*pr_baa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72cd1a45-22aa-4a2e-a10a-58b752bc7d1a",
      "metadata": {
        "id": "72cd1a45-22aa-4a2e-a10a-58b752bc7d1a"
      },
      "source": [
        "#### Step 5: Quantifying potential costs\n",
        "The potential costs methodology estimate the costs of removing biomass on per ton basis using machine rates and spatial analyses. Transportation costs are estimated using OSM roads segments, the rate of travel presented in **Table 2**, and log truck machine rates presented in **Table 3**. Extraction costs are estimated using **Table 3** machine rates. The potential treatment cost estimation approach is described in detail in [Hogland et. al. 2018](https://www.mdpi.com/2220-9964/7/4/156) and [2021](https://www.mdpi.com/1999-4907/12/8/1084)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a9b2db",
      "metadata": {
        "id": "08a9b2db"
      },
      "source": [
        "**Table 2**. Road segment travel speed by [OSM highway](https://wiki.openstreetmap.org/wiki/Key:highway) class types.\n",
        "\n",
        "|Query|Speed (MPH)|\n",
        "|:-|:-:|\n",
        "|Residential|25|\n",
        "|Unclassified|15|\n",
        "|Tertiary|35|\n",
        "|Secondary|45|\n",
        "|Primary|55|\n",
        "|Trunk|55|\n",
        "|Motorway|65|"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b8b72d",
      "metadata": {
        "id": "86b8b72d"
      },
      "source": [
        "**Table 3**. Criteria used to spatially define harvesting systems and treatment costs. Machine rate of travel, and capacity estimates derived from meetings with Lisa Ball, Jacob Baker, Michael Jow, and Brian McCrory. Tons = bone dry.\n",
        "\n",
        "|Component|System|Rate|Rate of travel|Payload|Where it can occur|\n",
        "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
        "|       |Rubber tire skidder|\\$165/hr|1.5 MPH|1.5 Tons|Slopes <= 35% and Next to Roads ( distance < 1510 ft from a road).|\n",
        "|Offroad|Skyline|\\$400/hr|2.0 MPH|1.25 Tons|Slopes > 35% and within 1000 ft of a road.|\n",
        "|       |Helicopter|\\$8,000/hr|2.4 MPH|2 Tons|Areas not covered by the other two and distance < 3000 ft from landing area.|\n",
        "|Felling|Feller buncher|\\$14.80/Ton|NA|NA|Slopes <= 35%|\n",
        "|       |Hand Felling|\\$26.67/Ton|NA|NA|Slopes > 35%|\n",
        "|Processing|Delimbing, cutting to length, chipping, and loading|\\$50.11/Ton|NA|NA|NA|\n",
        "|On road|Log Truck|\\$98/hour|Table 1|13 Tons|NA|\n",
        "|Additional Treatments|Hand Treatment|\\$0/acre|NA|NA|Forested Areas|\n",
        "|       |Prescribed fire|\\$210/acre|NA|NA|Forested Areas|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a9a6df",
      "metadata": {
        "id": "03a9a6df"
      },
      "outputs": [],
      "source": [
        "h_speed={'residential':40,'unclassified':24,'tertiary':56,'secondary':72,'primary':88,'trunk':88,'motorway':105} #kph units in meters\n",
        "\n",
        "#offroad rates of travel kph units in meters\n",
        "sk_r=2.4\n",
        "cb_r=3.2\n",
        "hl_r=3.8\n",
        "\n",
        "#component rates $ per hour or unit area\n",
        "sk_d=165\n",
        "cb_d=400\n",
        "hl_d=8000\n",
        "fb_d=14.80\n",
        "hf_d=26.67\n",
        "pr_d=50.11\n",
        "lt_d=98\n",
        "ht_d=0\n",
        "pf_d=210\n",
        "\n",
        "#payloads ton\n",
        "sk_p=1.5\n",
        "cb_p=1.25\n",
        "hl_p=2\n",
        "lt_p=13\n",
        "\n",
        "#set speed for road segments\n",
        "snf_roads['speed']=snf_roads['highway'].map(h_speed)\n",
        "tms=snf_roads.maxspeed.str.slice(0,2)\n",
        "snf_roads['speed'].where(snf_roads['maxspeed'].isna(),tms)\n",
        "snf_roads['conv']=2*(((1/(snf_roads['speed']*1000))*lt_d)/lt_p) #1000 converts kilometers per hour to meters per hour; round trip (2*)\n",
        "\n",
        "#snap sawmill facility to road vertices\n",
        "print(\"Snapping sawmills to roads\")\n",
        "smill_b=gpd.GeoDataFrame(geometry=sawmill).to_crs(snf_dem.crs)\n",
        "tmp_rds=snf_roads\n",
        "tmp_rds_seg=tmp_rds.sindex.nearest(smill_b.geometry,return_all=False)[1]\n",
        "lns=tmp_rds.iloc[tmp_rds_seg].geometry.values\n",
        "smill_b['cline']=lns\n",
        "smill_b['npt']=smill_b.apply(lambda row: row['cline'].interpolate(row['cline'].project(row['geometry'].centroid)),axis=1)#, result_type = 'expand')\n",
        "saw=Vector(smill_b.set_geometry('npt').set_crs(smill_b.crs))\n",
        "\n",
        "#create barriers to off road skidding\n",
        "bar2=(d_water>0).set_null_value(0)\n",
        "\n",
        "\n",
        "# create slope and road distance surfaces\n",
        "print(\"Creating base layers to threshold\")\n",
        "slp = slp_rs.eval() #compute so that slope only needs to be calculated once\n",
        "c_rs = creation.constant_raster(snf_dem).set_null_value(0) #constant value of 1 to multiply by distance\n",
        "rds_rs = (Vector(snf_roads).to_raster(snf_dem,'conv').set_null_value(0)) #source surface with all non-road cells (value of zero) set to null\n",
        "\n",
        "\n",
        "# convert on road rates and payload into on road cost surface that can be multiplied by the surface distance along a roadway to estimate hauling costs\n",
        "print(\"Calculating on road hauling costs\")\n",
        "saw_rs=(saw.to_raster(snf_dem).set_null_value(0))\n",
        "on_d_saw = distance.cda_cost_distance(rds_rs,saw_rs,snf_dem)\n",
        "\n",
        "# convert onroad surfaces to source surfaces measured in cents / ton\n",
        "src_saw = (on_d_saw * 100).astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58bd02de",
      "metadata": {
        "id": "58bd02de"
      },
      "outputs": [],
      "source": [
        "# create offroad surface distance surfaces that can be multiplied by rates to estimate dollars per unit\n",
        "print(\"Calculating offroad costs\")\n",
        "\n",
        "#barriers to motion\n",
        "b_dst_cs2=bar2#.set_null_value(0) # skidding and cable\n",
        "\n",
        "#calc distance\n",
        "saw_d,saw_t,saw_a=distance.cost_distance_analysis(b_dst_cs2,src_saw,snf_dem)\n",
        "saw_d=saw_d.where(saw_d>0,np.nan)\n",
        "saw_d=saw_d.where(saw_a>0,np.nan)\n",
        "\n",
        "# Onroad, offroad, Felling, processing costs, and Additional Treatments\n",
        "print(\"Calculating additional felling, processing, and treatment costs\")\n",
        "f1=slp<=0.35\n",
        "fell=(f1*fb_d).where(f1,hf_d)\n",
        "prc=creation.constant_raster(snf_dem,pr_d).astype(float)\n",
        "oc=fell+prc\n",
        "\n",
        "#Additional treatment costs (per/ha)\n",
        "ht_cost=creation.constant_raster(snf_dem,(ht_d*0.222395)).astype(float) #0.222395 acres per cell\n",
        "pf_cost=creation.constant_raster(snf_dem,(pf_d*0.222395)).astype(float) #0.222395 per cell\n",
        "#add_treat_cost=a_t*frst\n",
        "\n",
        "# Convert offroad rates to a mulitiplier that can be used to calculate dollars per ton given distance\n",
        "print(\"Combining costs...\")\n",
        "s_c= (2 * (((1/(sk_r*1000))*sk_d)/sk_p)) #round trip 2*\n",
        "c_c= (2 * (((1/(cb_r*1000))*cb_d)/cb_p)) #round trip 2*\n",
        "h_c= (2 * (((1/(hl_r*1000))*hl_d)/hl_p)) #round trip 2*\n",
        "\n",
        "# Calculate potential saw costs $/Ton\n",
        "sk_saw_cost=(saw_d * s_c) + oc\n",
        "cb_saw_cost=(saw_d * c_c) + oc\n",
        "hd_saw_cost=(saw_d * h_c) + oc\n",
        "\n",
        "# Operations\n",
        "rd_dist=distance.cda_cost_distance(c_rs,(rds_rs>0).astype(int),snf_dem)\n",
        "\n",
        "sk=f1 & (rd_dist<460)\n",
        "cb=((slp>0.35) & (rd_dist<305))*2\n",
        "skcb=sk+cb\n",
        "opr=(skcb.where(skcb>0,3) * (rd_dist<915)).astype(float)\n",
        "\n",
        "#Create final rasters\n",
        "o1=opr==1\n",
        "o2=opr==2\n",
        "o3=opr==3\n",
        "sc1=sk_saw_cost*o1\n",
        "sc2=cb_saw_cost*o2\n",
        "sc3=hd_saw_cost*o3\n",
        "\n",
        "# Calculate potential haul cost allocated $/Ton\n",
        "phaul=(saw_a/100)\n",
        "phaul=phaul.where(opr>0,0)\n",
        "\n",
        "saw_cost=sc1+sc2+sc3 #total cost $/ton to remove material\n",
        "\n",
        "add_tr_fr_cost=ht_cost+pf_cost #additional cost to implement prescribed burning and hand treatments\n",
        "add_tr_fr_cost=add_tr_fr_cost.where(opr>0,0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38a2f1a-ead2-44a9-ad6f-b828045bc705",
      "metadata": {
        "id": "b38a2f1a-ead2-44a9-ad6f-b828045bc705"
      },
      "source": [
        "#### Step 6: Linking potential cost with potential removals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f79a81",
      "metadata": {
        "id": "42f79a81"
      },
      "source": [
        "#### Defining potential treatment units\n",
        "While DFC may not be in alignment with our current condition at the cell level, one cell alone may not be worth the time and effort to setup and implement a operational treatment unit. Likewise, the difference between DFC and the existing condition may be so close at the cell level that a treatment is unwarranted. To identify operational treatment areas that meet both conditions (enough biomass and a large enough region) we will select all cells that have at least 3 tons of biomass needed to be removed and that when combined into a region of cells meeting that criteria account for at least 12 acres.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a0f0d0",
      "metadata": {
        "id": "c9a0f0d0"
      },
      "outputs": [],
      "source": [
        "#potential treatment units\n",
        "rgns=general.regions((ton_rm>3).astype('int32'),neighbors=4,unique_values=[1]).set_null_value(0) #find unique region\n",
        "vls, cnts=np.unique(rgns,return_counts=True) # summarize counts by each region\n",
        "df=pd.DataFrame({'regions':vls,'counts':cnts}) #convert to dataframe\n",
        "r_m_c=df[(df['counts']>55) & (df['regions']>0)] #select regions with counts greater than 55 (skip region 0, it is the background)\n",
        "rdic=r_m_c.reset_index().set_index('regions')['index'].to_dict() #convert to dictionary for remapping\n",
        "ptu=rgns.reclassify(rdic,True) # reclassify region map to index values for regions meeting criteria (potential treatment units; ptu)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54fe86db",
      "metadata": {
        "id": "54fe86db"
      },
      "source": [
        "#### Estimate potential cost, revenue, and profite at the cell level and summarize up to the treatment level ($130/ton bone dry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da20035",
      "metadata": {
        "id": "7da20035"
      },
      "outputs": [],
      "source": [
        "from raster_tools import zonal\n",
        "#potential cost\n",
        "pcost=ton_rm*saw_cost + ston_rm * phaul + add_tr_fr_cost#\n",
        "prev=ston_rm*130 #using $65/ton for gate prices (green and 50% water weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HUg0Asybxraf",
      "metadata": {
        "id": "HUg0Asybxraf"
      },
      "source": [
        "#### Summarize potential costs using potential treatment units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "542642dc",
      "metadata": {
        "id": "542642dc"
      },
      "outputs": [],
      "source": [
        "#convert ptu to polygons\n",
        "v_regions=ptu.to_polygons().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296c5fdb",
      "metadata": {
        "id": "296c5fdb"
      },
      "outputs": [],
      "source": [
        "#use zonal statistics to summarize cell values within each polygon\n",
        "st2=zonal.zonal_stats(v_regions,general.band_concat([pcost,prev,ton_rm,ston_rm]),'sum',features_field='value',wide_format=True)#\n",
        "st2=st2.compute()\n",
        "st2.columns= ['cost','revenue','ttons','stons'] #remove the 2 level index to merger data back to v_regions\n",
        "v_regions=v_regions.merge(st2,left_on='value',right_on='zone')\n",
        "v_regions['acres']=v_regions.area*0.000247105\n",
        "v_regions['ttons_acre']=v_regions['ttons']/v_regions['acres']\n",
        "v_regions['stons_acre']=v_regions['stons']/v_regions['acres']\n",
        "v_regions['cost_acre']=v_regions['cost']/v_regions['acres']\n",
        "v_regions['revenue_acre']=v_regions['revenue']/v_regions['acres']\n",
        "v_regions['cost_ton']=v_regions['cost']/v_regions['ttons']\n",
        "v_regions['revenue_ton']=v_regions['revenue']/v_regions['ttons']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693f4e80",
      "metadata": {
        "id": "693f4e80"
      },
      "outputs": [],
      "source": [
        "csdif=-1 #per ton\n",
        "chk=((v_regions.cost_ton > 0) & ((v_regions.revenue_ton-v_regions.cost_ton)>csdif)) #cost per acre $25\n",
        "vsub=v_regions[chk]\n",
        "print('Total acres treated =',vsub.acres.sum(),'Total profit =', (vsub.revenue-vsub.cost).sum(), 'Total tons removed =',vsub.ttons.sum(), 'Total tons delivered =',vsub.stons.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b57e5c",
      "metadata": {
        "id": "44b57e5c"
      },
      "outputs": [],
      "source": [
        "\n",
        "m=vsub.explore(column='stons_acre')\n",
        "m=snf_sawmill.explore(m=m,color='red')\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98f24e6",
      "metadata": {
        "id": "e98f24e6"
      },
      "outputs": [],
      "source": [
        "v_regions.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WymXsd_oTD7D",
      "metadata": {
        "id": "WymXsd_oTD7D"
      },
      "source": [
        "#### Display the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f0f2ad",
      "metadata": {
        "id": "88f0f2ad"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "display(v_regions)\n",
        "\n",
        "m=(snf.to_crs(snf_tlst.crs)).explore(color='red',name='NF Boundary')\n",
        "m=snf_pods.explore(m=m, color='orange',name='PODs')\n",
        "m=snf_sawmill.explore(m=m, color = 'yellow',name='Sawmill')\n",
        "m=v_regions.explore(m=m,column='cost_ton',legend=True,cmap='RdYlGn',name='Potential Units')\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
        "    attr=\"Esri\",\n",
        "    name=\"Esri Imagery\",\n",
        "    overlay=False,\n",
        "    control=True,\n",
        ").add_to(m)\n",
        "\n",
        "ton_rm.explore(band=1,cmap='PRGn',map=m, name='Ton Removed')\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082977be",
      "metadata": {
        "id": "082977be"
      },
      "outputs": [],
      "source": [
        "m.save('Umatilla_NF.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SPAEIkmjT1rC",
      "metadata": {
        "id": "SPAEIkmjT1rC"
      },
      "source": [
        "# This ends the Fire Resilence notebook\n",
        "## Check out the other notebooks:\n",
        "- https://github.com/UM-RMRS/raster_tools/blob/main/notebooks/README.md\n",
        "## References\n",
        "- Raster-Tools GitHub: https://github.com/UM-RMRS/raster_tools\n",
        "- Hogland's Spatial Solutions: https://sites.google.com/view/hoglandsspatialsolutions/home\n",
        "- Dask: https://dask.org/\n",
        "- Geopandas:https://geopandas.org/en/stable/\n",
        "- Xarray: https://docs.xarray.dev/en/stable/\n",
        "- Jupyter: https://jupyter.org/\n",
        "- Anaconda:https://www.anaconda.com/\n",
        "- VS Code: https://code.visualstudio.com/\n",
        "- ipywidgets: https://ipywidgets.readthedocs.io/en/latest/\n",
        "- numpy:https://numpy.org/\n",
        "- matplotlib:https://matplotlib.org/\n",
        "- folium: https://python-visualization.github.io/folium/\n",
        "- pandas: https://pandas.pydata.org/\n",
        "- sklearn: https://scikit-learn.org/stable/index.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "rstools",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
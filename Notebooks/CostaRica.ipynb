{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/CostaRica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-_uqy-BCF9"
      },
      "source": [
        "# Install geemap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4XOqjwqBCF-"
      },
      "outputs": [],
      "source": [
        "!pip install geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1r_6h6cBCF-"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUZAvlCrBCF-"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import geopandas as gpd, pandas as pd, os, numpy as np\n",
        "import ee, geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7GhCxo8BCF_"
      },
      "source": [
        "## Authenticate and Initialize the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdGzj2Z1BCF_"
      },
      "outputs": [],
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-jshogland') #you will want to select your personal cloud project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL-nBLTjBCF_"
      },
      "source": [
        "# Read the shape file into a geodataframe\n",
        "## Display CRS and column names\n",
        "\n",
        "### If running on Colab you will need to upload the Clasification_Plot.zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svLTzKbtBCF_"
      },
      "outputs": [],
      "source": [
        "gdf=gpd.read_file('Clasification_Plots.zip')\n",
        "display(gdf.crs)\n",
        "display(gdf.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9xk7eeqBCF_"
      },
      "source": [
        "## Subset the geodataframe to the columns we are interested in and display the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmQcc7zBBCGA"
      },
      "outputs": [],
      "source": [
        "k_clms = ['plotid','sampleid','Vegetacion','Herbaceas', 'Pasto_Arb', 'Cultivo','Humedal', 'Terreno','Agua','Otra_clase','SAF','Cambios15_','Gana_Perdi','geometry']\n",
        "gdf_s=gdf[k_clms]\n",
        "gdf_s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfjmDGhRBCGA"
      },
      "source": [
        "## Display summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMeAq69UBCGA"
      },
      "outputs": [],
      "source": [
        "display(gdf_s.describe())\n",
        "display(gdf.describe(include='object'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5F0jF9TBCGA"
      },
      "source": [
        "## Make GeoSeries of the study area and create convex hull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9tjyQJYBCGA"
      },
      "outputs": [],
      "source": [
        "chul=gpd.GeoSeries(gdf_s.unary_union.convex_hull,crs=gdf_s.crs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F2ti_fGBCGA"
      },
      "source": [
        "## Create definitions for the median and medoid procedures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYrApRgxBCGA"
      },
      "outputs": [],
      "source": [
        "def maskL8sr(image):\n",
        "    # Bit 0 - Fill\n",
        "    # Bit 1 - Dilated Cloud\n",
        "    # Bit 2 - Cirrus\n",
        "    # Bit 3 - Cloud\n",
        "    # Bit 4 - Cloud Shadow\n",
        "    qaMask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
        "    saturationMask = image.select('QA_RADSAT').eq(0)\n",
        "    # Apply the scaling factors to the appropriate bands.\n",
        "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
        "    thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
        "    #Replace the original bands with the scaled ones and apply the masks.\n",
        "    return image.addBands(opticalBands, overwrite=True).addBands(thermalBands, overwrite=True).updateMask(qaMask).updateMask(saturationMask)\n",
        "\n",
        "def median_mosaic(image,fltr=None,refl_bands=['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']):\n",
        "    if(fltr is None):\n",
        "        inCollection = image.filter(fltr).select(refl_bands)\n",
        "    else:\n",
        "        inCollection = image.filter(fltr).select(refl_bands)\n",
        "\n",
        "    return inCollection.median()\n",
        "\n",
        "def _medoid(col):\n",
        "    median = ee.ImageCollection(col).median()\n",
        "    diff=ee.Image(col).subtract(median).pow(ee.Image.constant(2))\n",
        "    return diff.reduce('sum').addBands(col)\n",
        "\n",
        "\n",
        "def medoid_mosaic(image, fltr,refl_bands=['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']):\n",
        "    if(fltr is None):\n",
        "        inCollection = image.filter(fltr).select(refl_bands)\n",
        "    else:\n",
        "        inCollection = image.filter(fltr).select(refl_bands)\n",
        "\n",
        "    medoid = inCollection.map(_medoid)\n",
        "    medoid = ee.ImageCollection(medoid).reduce(ee.Reducer.min(7)).select([1,2,3,4,5,6], refl_bands)\n",
        "    return medoid\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXr-FKeUBCGA"
      },
      "source": [
        "## Set various variable and create the mdoid surface on ee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwMCPpzeBCGB"
      },
      "outputs": [],
      "source": [
        "#make lists fo band names for selections\n",
        "lc8_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'ST_B10', 'QA_PIXEL']#landsat band names\n",
        "tgt_bands = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2', 'TEMP', 'QA_PIXEL']#common band names\n",
        "refl_bands = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']#bands we care about\n",
        "\n",
        "#specify start and end dates for the image filter\n",
        "startDate = '2021-01-01'\n",
        "endDate = '2024-07-01'\n",
        "\n",
        "#Specify julian dates for filter. Here we want to select sunny months\n",
        "julianStart1 = 350# Starting Julian Date (for landsat median cloud free )\n",
        "julianEnd1 = 365\n",
        "julianStart2 = 1\n",
        "julianEnd2 = 150# Ending Julian date (for landsat median cloud free)\n",
        "\n",
        "#define the study area extent from our convex hull\n",
        "#geo=geemap.gdf_to_ee(gpd.GeoDataFrame(geometry=chul)) #convert our convex hull into a ee feature class object\n",
        "\n",
        "#make the ee collection\n",
        "l8_col=ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n",
        "\n",
        "#set various filters\n",
        "#f_bnds=ee.Filter.bounds(geometry=geo)\n",
        "f_date=ee.Filter.date(startDate,endDate)\n",
        "f_cr1=ee.Filter.calendarRange(julianStart1,julianEnd1)\n",
        "f_cr2=ee.Filter.calendarRange(julianStart2,julianEnd2)\n",
        "f_or=ee.Filter.Or(f_cr1,f_cr2)\n",
        "f_and=ee.Filter.And(f_date,f_or)\n",
        "\n",
        "#use our filter on the landsat collection\n",
        "l8=l8_col.filter(f_and).map(maskL8sr)\n",
        "l8r=l8.select(lc8_bands,tgt_bands)\n",
        "\n",
        "#call the medoid function\n",
        "medoid = medoid_mosaic(l8r,fltr=f_and,refl_bands=refl_bands)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aKfrArRBCGB"
      },
      "source": [
        "## Create a generic Map using geemap and then map the DEM and Medoid surface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCIFEhg2BCGB"
      },
      "outputs": [],
      "source": [
        "Map = geemap.Map()\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACsvcXgdBCGB"
      },
      "source": [
        "### Add the EE layers to the map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzIb3TwjBCGB"
      },
      "outputs": [],
      "source": [
        "# get the dem from EE\n",
        "dem = ee.Image(\"USGS/SRTMGL1_003\")\n",
        "\n",
        "# Set visualization parameters for the map.\n",
        "vis_params = {\n",
        "    \"min\": 0,\n",
        "    \"max\": 4000,\n",
        "    \"palette\": [\"006633\", \"E5FFCC\", \"662A00\", \"D8D8D8\", \"F5F5F5\"],\n",
        "}\n",
        "\n",
        "#Add Earth Engine layers to Map\n",
        "Map.addLayer(\n",
        "    medoid, {\"bands\": [\"RED\", \"GREEN\", \"BLUE\"],\n",
        "             'min':-0.02,\n",
        "             'max':0.3\n",
        "    },\n",
        "    \"Landsat 8\",\n",
        ")\n",
        "\n",
        "Map.addLayer(dem, vis_params, \"SRTM DEM\", True, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Sq-BMSBCGB"
      },
      "source": [
        "## Extract DEM and Medoid pixel values\n",
        "\n",
        "### Due to memory limitation on EE, we will need to subset our data and send multiple requests\n",
        "#### Let's start with making a function to handle splitting up the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEb7zanoBCGB"
      },
      "outputs": [],
      "source": [
        "def get_tiles(gdf,ntiles):\n",
        "    chul=gpd.GeoSeries(gdf.unary_union.convex_hull,crs=gdf.crs)\n",
        "    xmin,ymin,xmax,ymax=chul.total_bounds\n",
        "    sp=(np.sqrt(chul.area/ntiles))[0]\n",
        "    sp2=(sp/2)\n",
        "    xs=np.arange(xmin-sp2,xmax+sp2,sp)\n",
        "    ys=np.arange(ymin-sp2,ymax+sp2,sp)\n",
        "    xv, yv = np.meshgrid(xs, ys)\n",
        "    xv = xv.flatten()\n",
        "    yv = yv.flatten()\n",
        "    pnts = gpd.GeoSeries(gpd.points_from_xy(x=xv, y=yv),crs=gdf.crs)\n",
        "    buff = pnts.buffer(sp2,cap_style='square')\n",
        "    buff = buff[buff.intersects(gdf.unary_union)]\n",
        "    return buff\n",
        "\n",
        "def extract_data(gdf,img,ntiles,stats='FIRST',scale=30):\n",
        "    '''\n",
        "    Iteratively calls EE and extracts data from the image\n",
        "    gdf = (geodataframe) of features used to extract values\n",
        "    img = (ee image object) ee image to extract values from\n",
        "    ntiles = (int) number of tiles used to extract data at a time\n",
        "    column_names = (list[string]) list of column names to for output dataframe\n",
        "    stats= (string) name of the ee static (e.g., FIRST, MEAN, MAX, MIN, MEDIAN, etc.)\n",
        "\n",
        "    returns a Dataframe of values (one record for each observation in the gdf)\n",
        "    '''\n",
        "    tls=get_tiles(gdf,ntiles)\n",
        "    ogdf=gdf.copy()\n",
        "    for t in tls:\n",
        "        sel=ogdf.intersects(t)\n",
        "        sdf=ogdf[['geometry']][sel]\n",
        "        #use try and except catch errors\n",
        "        try:\n",
        "            fc=geemap.gdf_to_ee(sdf) #convert your subset geodataframe into a ee feature class object\n",
        "            outfc=geemap.extract_values_to_points(fc,img,stats_type=stats,scale=scale) #extract the image values for each point location.\n",
        "            ogdf2=geemap.ee_to_gdf(outfc).drop(['geometry'],axis=1) #convert your output ee object into a geodataframe\n",
        "            column_names=ogdf2.columns\n",
        "            ogdf.loc[sel,column_names]=ogdf2.values #update records of our geodataframe\n",
        "        except Exception as e:\n",
        "            print('Error: ',e)\n",
        "\n",
        "    return ogdf #return the geodataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrMnf4tuBCGB"
      },
      "source": [
        "### Let's extract our dem and medoid data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEkKiuEJBCGB"
      },
      "outputs": [],
      "source": [
        "#get dem values\n",
        "dem_tbl=extract_data(gdf_s,dem,100) #no reducers can take bigger tiles (less ram on server to process)\n",
        "medoid_tbl=extract_data(gdf_s,medoid,500) #need to increase tiles to account for reducers (ram limits on server)\n",
        "display(dem_tbl)\n",
        "display(medoid_tbl)\n",
        "#How many calls to EE?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFsWfB7MPz-x"
      },
      "source": [
        "## Let's create our other predictor surfaces (pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zvJIXHaPyoh"
      },
      "outputs": [],
      "source": [
        "# get NDVI from medoid\n",
        "ndvi = medoid.normalizedDifference(['NIR', 'RED']).rename('ndvi')\n",
        "\n",
        "#evi\n",
        "evi = medoid.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
        "                        {\n",
        "                            'NIR': medoid.select('NIR'),\n",
        "                            'RED': medoid.select('RED'),\n",
        "                            'BLUE': medoid.select('BLUE')\n",
        "                        }).rename('evi')\n",
        "\n",
        "#savi\n",
        "savi = medoid.expression('(NIR - RED) / (NIR + RED + .5) * (1 + .5)',\n",
        "                         {\n",
        "                             'NIR': medoid.select('NIR'),\n",
        "                             'RED': medoid.select('RED')\n",
        "                         }).rename('savi')\n",
        "\n",
        "\n",
        "#diff index\n",
        "diff = medoid.select('NIR').subtract(medoid.select('RED')).rename('diff')\n",
        "\n",
        "#Tasseled cap\n",
        "coefficients = {\n",
        "  'brightness': [0.3029, 0.2786, 0.4733, 0.5599, 0.508, 0.1872],\n",
        "  'greenness': [-0.2941, -0.243, -0.5424, 0.7276, 0.0713, -0.1608],\n",
        "  'wetness': [0.1511, 0.1973, 0.3283, 0.3407, -0.7117, -0.4559],\n",
        "}\n",
        "\n",
        "#Calculate Tasseled Cap The band order is Blue, Green, Red, NIR, SWIR1, SWIR2.\n",
        "brightness = medoid.select(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).multiply(coefficients['brightness']).reduce('sum').rename('brightness')\n",
        "greenness = medoid.select(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).multiply(coefficients['greenness']).reduce('sum').rename('greenness')\n",
        "wetness = medoid.select(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']).multiply(coefficients['wetness']).reduce('sum').rename('wetness')\n",
        "\n",
        "#Elevation and derivatives\n",
        "# Calculate terrain layers\n",
        "slope = ee.Terrain.slope(dem)\n",
        "aspect = ee.Terrain.aspect(dem).rename('aspect')\n",
        "\n",
        "# Aspect transforms\n",
        "aspectDeg = aspect.unitScale(-180, 180).rename('aspectdeg')\n",
        "cosAspect = aspectDeg.cos().rename('aspectcos')\n",
        "sinAspect = aspectDeg.sin().rename('aspectsin')\n",
        "\n",
        "#Canopy Height\n",
        "altura2 = ee.Image('users/nlang/ETH_GlobalCanopyHeight_2020_10m_v1').rename(['altura2'])\n",
        "\n",
        "#Height above nearest drainage\n",
        "hand30_100 = ee.ImageCollection(\"users/gena/global-hand/hand-100\").mosaic().rename(['hand30_100'])\n",
        "\n",
        "#soils\n",
        "clay_1mMed = ee.Image(\"projects/soilgrids-isric/clay_mean\").unmask(0).multiply([.05,.10,.15,.30,.40,0]).reduce('sum').rename('clay_1mMed')\n",
        "sand_1mMed = ee.Image(\"projects/soilgrids-isric/sand_mean\").unmask(0).multiply([.05,.10,.15,.30,.40,0]).reduce('sum').rename('sand_1mMed')\n",
        "silt_1mMed = ee.Image(\"projects/soilgrids-isric/silt_mean\").unmask(0).multiply([.05,.10,.15,.30,.40,0]).reduce('sum').rename('silt_1mMed')\n",
        "ocs_1mMed = ee.Image(\"projects/soilgrids-isric/ocs_mean\").unmask(0).multiply([.05,.10,.15,.30,.40,0]).reduce('sum').rename('ocs_1mMed')\n",
        "\n",
        "#LAI\n",
        "wgs_500m_8d = ee.ImageCollection(\"projects/sat-io/open-datasets/BU_LAI_FPAR/wgs_500m_8d\")\n",
        "fparProc = wgs_500m_8d.filter(f_and).median().select('FPAR').multiply(0.01).unmask(0).rename('fpar')\n",
        "laiProc = wgs_500m_8d.filter(f_and).median().select('LAI').multiply(0.01).unmask(0).rename('lai')\n",
        "\n",
        "#Topograghic indices\n",
        "topDIV = ee.Image('CSP/ERGo/1_0/Global/SRTM_topoDiversity').add(1323.63).rename('topDiv')\n",
        "mTPI = ee.Image(\"CSP/ERGo/1_0/Global/SRTM_mTPI\").add(8129).rename('mTPI')\n",
        "\n",
        "#make a list of predictors\n",
        "pred2_lst=[medoid,dem,savi,diff,evi,brightness,wetness,ndvi,slope,aspect,\n",
        "           aspectDeg,cosAspect,sinAspect,altura2,clay_1mMed,sand_1mMed,silt_1mMed,\n",
        "           ocs_1mMed,fparProc,laiProc,hand30_100,topDIV,mTPI]\n",
        "\n",
        "# let's combine our pred2 surfaces into one Raster\n",
        "pred2=ee.Image(pred2_lst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Icv3uDUP-tg"
      },
      "source": [
        "### Now let's extract pred2 values\n",
        "#### We are extracting all predictor values this time including modoid and elevation. This is redundant to the other extraction piece meaning we did not need to run the other cell. We could have run it all in one cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zeO9ycKP-WK"
      },
      "outputs": [],
      "source": [
        "gdf_f=extract_data(gdf_s,pred2,500,'FIRST',scale=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF7Qbx_JBCGB"
      },
      "source": [
        "### Let's look at our dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zWLOMEXBCGB"
      },
      "outputs": [],
      "source": [
        "gdf_f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHZZ17t9Ab2t"
      },
      "source": [
        "## Is there any missing data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbirCW7JAbZ0"
      },
      "outputs": [],
      "source": [
        "gdf_f.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPR7TJsA_TAS"
      },
      "source": [
        "## Save out the dataframe. If in Colab, don't forget to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Beh7O0_u_WDL"
      },
      "outputs": [],
      "source": [
        "#as a shape file\n",
        "gdf_f.to_file('CostaRica_EE_data.shp')\n",
        "\n",
        "#as a csv\n",
        "gdf_f.to_csv('CostaRica_EE_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJAJyzNKp8cy"
      },
      "source": [
        "## Let's visually look at all savi records that have nans by adding those locations to our map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MCxYJoLnmes"
      },
      "outputs": [],
      "source": [
        "fc=geemap.gdf_to_ee(gdf_f[gdf_f['savi'].isna()])\n",
        "Map.addLayer(fc,name='SAVI NANs',vis_params={'color':'yellow'})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rstools",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

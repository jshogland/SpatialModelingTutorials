{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/glcm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing one pass gray level co-occurrence matrix (GLCM) for any bit depth, without using a co-occurrence probability matrix.\n",
    "This notebook documents how to calculate GLCM metrics using an alterative, one pass processing technique. This technique does not require specifying bit depth, bypasses creating a co-occurrence matrix, allows for implementation within a moving windows context, and is adapted to work within the Raster Tools processing architecture.\n",
    "\n",
    "by John Hogland 2/6/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLCMs are often used in computer vision to quantify neighboring pixel relationships (metrics) within a image. While often used across an entire image, GLCMs metrics can be useful if calculated for subregions of an image or even within a moving window context. However, current approaches that use a co-occurrence probability matrix to process GLCM metrics are slow. Our new and novel approach remove this unnecessary step and quantifies GLCM metric values using an optimized, one pass technique. Using this technique, we demonstrate how to implement GLCMs within Raster Tools processing architecture. In this notebook the following metrics are calculated for a portion of Landsat 8 scene located in southern Montana USA:\n",
    "- contrast\n",
    "- dissimilarity\n",
    "- homogeneity\n",
    "- ASM\n",
    "- energy\n",
    "- correlation\n",
    "- mean\n",
    "- variance\n",
    "- std\n",
    "- entropy   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages to run on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mapclassify\n",
    "!pip install osmnx\n",
    "!pip install raster_tools\n",
    "!pip install planetary-computer\n",
    "!pip install pystac-client\n",
    "!pip install stackstac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, geopandas as gpd, numba as nb, osmnx as ox, pystac_client, planetary_computer, stackstac\n",
    "from raster_tools import raster, Raster, general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The study area\n",
    "#### Get the boundary data for portions of the Custer Gallatin National Forest and create a interactive location map of the study (Figure 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "#use OpenStreetMaps to get the boundary of the NF\n",
    "nf=ox.geocode_to_gdf('Custer Gallatin National Forest, MT, USA')\n",
    "\n",
    "#get first polygon of the NF\n",
    "nfe=nf.explode()\n",
    "nf1=gpd.GeoSeries(nfe.geometry.iloc[10],crs=nf.crs)\n",
    "\n",
    "#project to Albers equal area\n",
    "nf1p=nf1.to_crs(5070)\n",
    "\n",
    "#Visualize the nf1 and sample locations\n",
    "m=nf1p.explore(color='red',style_kwds=dict(fill=False,weight=5),name='Boundary')\n",
    "folium.TileLayer(\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name=\"Esri Imagery\",\n",
    "    overlay=False,\n",
    "    control=True,\n",
    ").add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 1.__ Interactive location map of the study area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get Landsat 8 Imagery\n",
    "Create download definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create definition to mosaic stac data\n",
    "def mosaic_stac(xr):\n",
    "    return stackstac.mosaic(xr)\n",
    "\n",
    "#create definition to extract stac data\n",
    "def get_stac_data(geo,url=\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"sentinel-2-l2a\",res=30,crs=5070,**kwarg):\n",
    "    '''\n",
    "    gets tiled data from planetary computer as a dask backed xarray that intersects the geometry of the point, line, or polygon\n",
    "\n",
    "    geo = (polygon) geometry bounding box (WGS84)\n",
    "    url = (string) base url to planetary computer https://planetarycomputer.microsoft.com/api/stac/v1\n",
    "    name = (string) catelog resource\n",
    "    qry =  (dictoinary) of property values {'eo:cloud_cover':{'lt':1}}\n",
    "    res = (tuple of numbers) output resolution (x,y)\n",
    "    crs = (int) output crs\n",
    "    dt = (string) data time intervale e.g., one month: 2023-06, range: 2023-06-02/2023-06-17\n",
    "    limit = (int) max number of items to return\n",
    "\n",
    "    returns (xarray data array and stac item catalog)\n",
    "    '''\n",
    "    catalog = pystac_client.Client.open(url, modifier=planetary_computer.sign_inplace)\n",
    "    srch = catalog.search(collections=name, intersects=geo, **kwarg)\n",
    "    ic = srch.item_collection()\n",
    "    if(len(ic.items)>0):\n",
    "        xra = stackstac.stack(ic,resolution=res,epsg=crs)\n",
    "        xra = mosaic_stac(xra)\n",
    "    else:\n",
    "        xra=None\n",
    "\n",
    "    return xra,ic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data and create a raster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stac data landsat data\n",
    "if(not os.path.exists('ls82016.tif')):\n",
    "    xmin,ymin,xmax,ymax=nf1p.buffer(200).total_bounds\n",
    "    ls30, ic =get_stac_data(nf1.geometry[0],\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"landsat-c2-l2\",res=30,crs=5070,datetime='2016-06-15/2016-06-30',query={'eo:cloud_cover':{'lt':10},'platform':{'eq':'landsat-8'}},limit=1000)\n",
    "    ls30s=Raster(ls30.sel(band=['red', 'green', 'blue','nir08', 'lwir11','swir16', 'swir22'],x=slice(xmin,xmax),y=slice(ymax,ymin)))\n",
    "    ls30s=ls30s.save('ls82016.tif')\n",
    "\n",
    "ls30s=Raster('ls82016.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the study area and the Landsat 8 image (Figure 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=nf1p.plot(edgecolor='red',facecolor='none',figsize=(15,10),linewidth=5)\n",
    "p=ls30s.get_bands([1,2,3]).xdata.plot.imshow(ax=p,robust=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 2.__ Overlay of Landsat 8 image subset (RGB bands) and the study area boundary outline in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create GLCMs\n",
    "#### Create definitions to create GLCM Raster datasets. \n",
    "These GLCM functions do not require setting levels or building a probability matrix. If you want to use levels, you can change the data type of the input raster to the desired bit depth or rescale the raster to the level desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLCM\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_vl(img,glcm,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
    "    ovl=0\n",
    "    if(glcm=='contrast'):\n",
    "        ovl=_get_contrast(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    elif(glcm=='dissimilarity'):\n",
    "        ovl=_get_dissimilarity(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    elif(glcm=='homogeneity'):\n",
    "        ovl=_get_homogeneity(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    elif(glcm=='ASM'):\n",
    "        ovl=_get_asm(img,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
    "    elif(glcm=='energy'):\n",
    "        ovl=_get_energy(img,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
    "    elif(glcm=='entropy'):\n",
    "        ovl=_get_entropy(img,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
    "    elif(glcm=='correlation'):\n",
    "        ovl=_get_correlation(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    elif(glcm=='variance'):\n",
    "        ovl=_get_variance(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    elif(glcm=='std'):\n",
    "        ovl=_get_std(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    else:\n",
    "        ovl=_get_mean(img,rstart,rws,cstart,clms,roff,coff,n)\n",
    "    return ovl\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_contrast(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    s=0\n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=img[r,c]\n",
    "            v2=img[r+roff,c+coff]\n",
    "            dif=v1-v2\n",
    "            vl= dif*dif*2\n",
    "            s+=vl\n",
    "    return s/n\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_mean(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    s=0\n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=img[r,c]\n",
    "            v2=img[r+roff,c+coff]\n",
    "            vl=v1+v2\n",
    "            s+=vl\n",
    "    return s/n\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_dissimilarity(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    s=0\n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=img[r,c]\n",
    "            v2=img[r+roff,c+coff]\n",
    "            vl=np.abs(v1-v2)*2\n",
    "            s+=vl\n",
    "    return s/n\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_homogeneity(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    s=0\n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=img[r,c]\n",
    "            v2=img[r+roff,c+coff]\n",
    "            dif=v1-v2\n",
    "            vl= 2/(1+(dif*dif))\n",
    "            s+=vl\n",
    "    return s/n\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_array(img,rstart,rws,cstart,clms,roff,coff,levels):\n",
    "    #dic={}\n",
    "    p_arr=np.zeros((levels,levels))\n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=int(img[r,c])\n",
    "            v2=int(img[r+roff,c+coff])\n",
    "            p_arr[v1,v2]+=1\n",
    "            p_arr[v2,v1]+=1\n",
    "     \n",
    "    return p_arr\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_entropy(img,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
    "    p = _get_array(img,rstart,rws,cstart,clms,roff,coff,levels)\n",
    "    rws2,clms2=p.shape\n",
    "    s=0\n",
    "    for r in range(rws2):\n",
    "        for c in range(clms2):\n",
    "            v=p[r,c]\n",
    "            vl=v/n+0.00000000001\n",
    "            s+=-1*vl*np.log(vl)\n",
    "    \n",
    "    return s\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_asm(img,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
    "    p = _get_array(img,rstart,rws,cstart,clms,roff,coff,levels)\n",
    "    rws2,clms2=p.shape\n",
    "    s=0\n",
    "    for r in range(rws2):\n",
    "        for c in range(clms2):\n",
    "            v=p[r,c]\n",
    "            vl=v/n\n",
    "            s+=vl*vl\n",
    "\n",
    "    return s\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_energy(img,rstart,rws,cstart,clms,roff,coff,n,levels):\n",
    "    return _get_asm(img,rstart,rws,cstart,clms,roff,coff,n,levels)**0.5\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_variance(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    s=0\n",
    "    s2=0\n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=img[r,c]\n",
    "            v2=img[r+roff,c+coff]\n",
    "            s+=v1+v2\n",
    "            s2+=v1**2+v2**2\n",
    "    return (s2-((s**2)/n))/n\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_std(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    return _get_variance(img,rstart,rws,cstart,clms,roff,coff,n)**0.5\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_correlation(img,rstart,rws,cstart,clms,roff,coff,n):\n",
    "    sxy=0\n",
    "    sx=0\n",
    "    sx2=0\n",
    "    \n",
    "    for r in range(rstart,rws):\n",
    "        for c in range(cstart,clms):\n",
    "            v1=img[r,c]\n",
    "            v2=img[r+roff,c+coff]\n",
    "            sx+=v1+v2\n",
    "            sx2+=v1**2+v2**2\n",
    "            sxy+=v1*v2\n",
    "            \n",
    "    \n",
    "    num=n*sxy*2-sx*sx\n",
    "    den=((n*sx2-sx**2)*(n*sx2-sx**2))**0.5\n",
    "    \n",
    "    return num/den\n",
    "    \n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_n(rws,clms,dist,dir):\n",
    "    n=1\n",
    "    if(dir==0):\n",
    "        n=(rws-dist)*2*clms\n",
    "    elif(dir==2):\n",
    "        n=2*rws*(clms-dist)\n",
    "    else:\n",
    "        n=(rws-dist)*(clms-dist)*2\n",
    "    return n\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _get_glcm(img,glcms,dists,dirs,levels):\n",
    "    out_arr=np.zeros((len(glcms),len(dists),len(dirs)))\n",
    "    gcnt=0\n",
    "    for glcm in glcms:\n",
    "        dcnt=0\n",
    "        for dist in dists:\n",
    "            drcnt=0\n",
    "            for dir in dirs:\n",
    "                rws,clms=img.shape\n",
    "                n=_get_n(rws,clms,dist=dist,dir=dir)\n",
    "                # s=0\n",
    "                coff=0\n",
    "                roff=0\n",
    "                rstart=0\n",
    "                cstart=0\n",
    "                if(dir==0):\n",
    "                    coff=dist\n",
    "                    clms=clms-coff\n",
    "                elif(dir==1):\n",
    "                    coff=dist\n",
    "                    roff=dist\n",
    "                    clms=clms-coff\n",
    "                    rws=rws-roff\n",
    "                elif(dir==2):\n",
    "                    roff=dist\n",
    "                    rws=rws-roff\n",
    "                else:\n",
    "                    roff=(dist)\n",
    "                    coff=(-1*dist)\n",
    "                    cstart=dist\n",
    "                    rws=rws-roff\n",
    "                out_arr[gcnt,dcnt,drcnt]=_get_vl(img,glcm,rstart,rws,cstart,clms,roff,coff,n,levels)\n",
    "                drcnt+=1\n",
    "            dcnt+=1\n",
    "        gcnt+=1\n",
    "    return out_arr    \n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _glcm(X,glcms,dists,dirs,wsize,levels):\n",
    "    ''' \n",
    "    Creates GLCM surfaces for a given array. Used with dask's map_overlap function.\n",
    "    \n",
    "    X = (array) numpy array\n",
    "    glcms = (list of glcm names) ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation', 'mean', 'variance', 'std', 'entropy']\n",
    "    dists = (list of cell offsets) [1,2,3...]\n",
    "    dirs = (list of offset directions) [0,1,2,3] 0=horzontal, 1=diagonal 1, 2=vertical, 3=diagonal 2\n",
    "    wsize = (int) window width\n",
    "    returns a 3d array with dimensions equal to the length of bnds*glcms*dists*dirs,rows,columns of the original image and parameters\n",
    "    '''\n",
    "    bnd,rws,clms=X.shape\n",
    "    hw=int(wsize/2)\n",
    "    lg=len(glcms)\n",
    "    ld=len(dists)\n",
    "    ldr=len(dirs)\n",
    "    outarr=np.zeros((bnd*lg*ld*ldr,rws,clms))\n",
    "    for b in range(bnd):\n",
    "        bndst=b*lg*ld*ldr\n",
    "        bndend=bndst+lg*ld*ldr\n",
    "        for r in range(0,rws-wsize):\n",
    "            nr=r+hw\n",
    "            for c in range(0,clms-wsize):\n",
    "                nc=c+hw\n",
    "                img= X[b,r:r+wsize,c:c+wsize]\n",
    "                vls=_get_glcm(img,glcms,dists,dirs,levels)\n",
    "                outarr[bndst:bndend,nr,nc]=vls.flatten()\n",
    "    return outarr\n",
    "\n",
    "def glcm_wd(rs,glcm='contrast',dist=1,dir=0,wsize=3,cat=8):\n",
    "    ''' \n",
    "    Creates GLCM Raster for a specified GLCM and window size.\n",
    "    \n",
    "    rs = (Raster) input raster\n",
    "    glcm = (string) glcm names ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation', 'mean', 'variance', 'std', 'entropy']\n",
    "    dist = (int) cell offsets) 1,2,3, or ...\n",
    "    dir = (int) offset directions) 0,1,2, or 3 0=horzontal, 1=diagonal 1, 2=vertical, 3=diagonal 2\n",
    "    wsize = (int) window width\n",
    "    cat = (int) optional values for ASM, energy, and entropy GLCM. For these GLCM metrics, raster cell values cannot be greater than the number of levels-1 \n",
    "    \n",
    "    returns a mutiband Raster with dimensions equal to the length of bnds*glcms*dists*dirs,rows,columns of the original image and parameters\n",
    "    '''\n",
    "    hw=int(wsize/2)\n",
    "    #use map overlap function to retrieve kernel cell values\n",
    "    darr = rs.data.map_overlap(\n",
    "        _glcm,\n",
    "        depth={0: 0, 1: hw, 2: hw},\n",
    "        trim=True,\n",
    "        boundary=0,\n",
    "        dtype='f8',\n",
    "        meta=np.array((),dtype='f8'),\n",
    "        glcms=[glcm],\n",
    "        dists=[dist],\n",
    "        dirs=[dir],\n",
    "        wsize=wsize,\n",
    "        levels=cat,\n",
    "    )\n",
    "    out_rs=raster.data_to_raster(darr,mask=rs.mask,x=rs.x,y=rs.y,affine=rs.affine,crs=rs.crs)\n",
    "    return out_rs    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create GLCM surfaces for neighboring pixels (1 pixel distance), in all four directions, within a 3 by 3 window. In total this process will create a 280 GLCM surfaces (7 bands * 10 GLCM metrics * 4 directions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsize=7 #adjust to desired size\n",
    "glcm_names=['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation', 'mean', 'variance', 'std', 'entropy']\n",
    "glcm_names2=['contrast', 'dissimilarity', 'homogeneity', 'correlation', 'mean', 'variance', 'std']\n",
    "rs_lst=[]\n",
    "for glcm in glcm_names:\n",
    "    for d in [0,1,2,3]:\n",
    "        rs_lst.append(glcm_wd(ls30s,glcm,1,d,wsize,256))\n",
    "\n",
    "glcm_rs=general.band_concat(rs_lst)\n",
    "glcm_rs.xdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the GLCMs for the near IR Landsat 8 band (band 4) and direction 0 (horizontal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "fig, ax=pyplot.subplots(ncols=2,nrows=5,figsize=(15,20))\n",
    "\n",
    "bnd=4 #select Landsat band\n",
    "dir=0 #select direction\n",
    "\n",
    "\n",
    "glcm_b_rs=glcm_rs.get_bands(list(np.arange((bnd-1)+(ls30s.nbands*dir),280,28)+1)) #select GLCMs for IR band\n",
    "\n",
    "for b in glcm_b_rs.band:\n",
    "    r=(b-1)//2\n",
    "    c=(b-1)%2\n",
    "\n",
    "    p=glcm_b_rs.get_bands(b).plot(robust=True,cmap='PRGn',ax=ax[r,c])\n",
    "    ax[r,c].title.set_text(glcm_names[b-1])\n",
    "    ax[r,c].axis('off')\n",
    "\n",
    "fig.suptitle('GLCMs for Landsat band '+str(bnd) + ', distance = 1, and direction = ' + str(dir),fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust window size, band, and direction to view GLCM textures for various parameter setting\n",
    "\n",
    "### Discussion \n",
    "This new approach is significantly faster than using a sparse probability matrix to create moving window GLCM surfaces and is faster when calculating GLCM metrics for raster aggregation. Moreover, this approach provides the flexibility to create various GLCM metrics within the Raster Tools processing framework, making it readily available to the geospatial community. Finally, these same functions can be used to create GLCM metrics for the entire image in a fraction of the time required to perform the same analysis using the co-occurrence probability matrix.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing to calculate each GLCM metric for the entire image using the new approach described and scikit image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To facilitate processing using skimage we need to convert the input data into positive integer values (uint8). This is only required for the Energy, ASM, and Entropy metric in the newer approach but was used to consistently compare runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_lst=[]\n",
    "for b in ls30s.band:\n",
    "    rs=ls30s.get_bands(b)\n",
    "    minv=rs.min().compute()\n",
    "    maxv=rs.max().compute()\n",
    "    t=(((rs-minv)/(maxv-minv))*254)\n",
    "    t2=t.set_null_value(255).astype('uint8')\n",
    "    rs_lst.append(t2)\n",
    "\n",
    "rs2=general.band_concat(rs_lst)\n",
    "imgs=rs2.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timing for new procedure\n",
    "- All GLCMs\n",
    "- 1 cell away\n",
    "- Horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, skimage\n",
    "\n",
    "iter=1000\n",
    "\n",
    "run_time_d={}\n",
    "\n",
    "for glcm in glcm_names:\n",
    "    t1=time.perf_counter()\n",
    "    for i in range(iter):\n",
    "        for b in range(imgs.shape[0]):\n",
    "            img = imgs[b]\n",
    "            _get_glcm(img,[glcm],[1],[0],256)\n",
    "    t2=time.perf_counter()\n",
    "    run_time_d[glcm]=t2-t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timing for skimage\n",
    "- All GLCMs\n",
    "- 1 cell away\n",
    "- Horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time_d2={}\n",
    "\n",
    "for glcm in glcm_names:\n",
    "    t1=time.perf_counter()\n",
    "    for i in range(iter):\n",
    "        for b in range(imgs.shape[0]):\n",
    "            img = imgs[b]\n",
    "            p=skimage.feature.graycomatrix(img,[1],[0],levels=256,symmetric=True,normed=True)\n",
    "            skimage.feature.graycoprops(p,glcm)\n",
    "    \n",
    "    t2=time.perf_counter()\n",
    "    run_time_d2[glcm]=t2-t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.DataFrame.from_dict(run_time_d,orient='index',columns=['newer approach'])\n",
    "df2=pd.DataFrame.from_dict(run_time_d2,orient='index',columns=['skimage approach'])\n",
    "df=pd.concat([df1,df2],axis=1)\n",
    "df.plot.bar(ylabel='Seconds',xlabel='GLCM',title='Processing time of ' + str(iter) + ' iterations',figsize=(12,8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

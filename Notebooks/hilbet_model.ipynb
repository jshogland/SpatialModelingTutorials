{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, geopandas as gpd, pandas as pd, osmnx as ox, pystac_client, planetary_computer, stackstac\n",
    "from raster_tools import Raster, general\n",
    "from raster_tools import raster\n",
    "from owslib.wcs import WebCoverageService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "#use OpenStreetMaps to get the boundary of the NF\n",
    "nf=ox.geocode_to_gdf('Custer Gallatin National Forest, MT, USA')\n",
    "\n",
    "#get first polygon of the NF\n",
    "nfe=nf.explode()\n",
    "nf1=gpd.GeoSeries(nfe.geometry.iloc[10],crs=nf.crs)\n",
    "\n",
    "#project to Albers equal area\n",
    "nf1p=nf1.to_crs(5070)\n",
    "\n",
    "#Visualize the nf1 and sample locations\n",
    "m=nf1p.explore(color='red',style_kwds=dict(fill=False,weight=5))\n",
    "folium.TileLayer(\n",
    "    tiles=\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\",\n",
    "    attr=\"Esri\",\n",
    "    name=\"Esri Imagery\",\n",
    "    overlay=False,\n",
    "    control=True,\n",
    ").add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create definition to mosaic stac data\n",
    "def mosaic_stac(xr):\n",
    "    return stackstac.mosaic(xr)\n",
    "\n",
    "#create definition to extract stac data\n",
    "def get_stac_data(geo,url=\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"sentinel-2-l2a\",res=30,crs=5070,**kwarg):\n",
    "    '''\n",
    "    gets tiled data from planetary computer as a dask backed xarray that intersects the geometry of the point, line, or polygon\n",
    "\n",
    "    geo = (polygon) geometry bounding box (WGS84)\n",
    "    url = (string) base url to planetary computer https://planetarycomputer.microsoft.com/api/stac/v1\n",
    "    name = (string) catelog resource\n",
    "    qry =  (dictoinary) of property values {'eo:cloud_cover':{'lt':1}}\n",
    "    res = (tuple of numbers) output resolution (x,y)\n",
    "    crs = (int) output crs\n",
    "    dt = (string) data time intervale e.g., one month: 2023-06, range: 2023-06-02/2023-06-17\n",
    "    limit = (int) max number of items to return\n",
    "\n",
    "    returns (xarray data array and stac item catalog)\n",
    "    '''\n",
    "    catalog = pystac_client.Client.open(url, modifier=planetary_computer.sign_inplace)\n",
    "    srch = catalog.search(collections=name, intersects=geo, **kwarg)\n",
    "    ic = srch.item_collection()\n",
    "    if(len(ic.items)>0):\n",
    "        xra = stackstac.stack(ic,resolution=res,epsg=crs)\n",
    "        xra = mosaic_stac(xra)\n",
    "    else:\n",
    "        xra=None\n",
    "\n",
    "    return xra,ic\n",
    "\n",
    "# Create definition for WCS download\n",
    "def get_wcs_data(url,ply,service_name='mrlc_download__nlcd_tcc_conus_2021_v2021-4',out_prefix = 'tcc'):\n",
    "    '''\n",
    "    Extracts saves an image from a WCS given url, polygon boundary, and service name. Images are saved in the same location as the notebook.\n",
    "    url = (string) path to wcs e.g. 'https://www.mrlc.gov/geoserver/mrlc_download/nlcd_tcc_conus_2021_v2021-4/wcs?'\n",
    "    ply = (geoseries or geodataframe) of the study area\n",
    "    service_name = (string) name of the service e.g. mrlc_download__nlcd_tcc_conus_2021_v2021-4\n",
    "    out_prefix = (string) prefix used to save each image\n",
    "\n",
    "    returns a Raster object\n",
    "    '''\n",
    "    wcs=WebCoverageService(url)\n",
    "    tcc=wcs.contents[service_name]\n",
    "    bbox=tuple(ply.total_bounds)\n",
    "    subsets=[('X',bbox[0],bbox[2]),('Y',bbox[1],bbox[3])]\n",
    "    rsp=wcs.getCoverage(identifier=[tcc.id],subsets=subsets,format='geotiff')\n",
    "    outpath='./'+out_prefix+'.tif'\n",
    "    with open(outpath,'wb') as file:\n",
    "        file.write(rsp.read())\n",
    "\n",
    "    return Raster(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stac data landsat data\n",
    "if(not os.path.exists('ls82016.tif')):\n",
    "    xmin,ymin,xmax,ymax=nf1p.buffer(200).total_bounds\n",
    "    ls30, ic =get_stac_data(nf1.geometry[0],\"https://planetarycomputer.microsoft.com/api/stac/v1\",name=\"landsat-c2-l2\",res=30,crs=5070,datetime='2016-06-15/2016-06-30',query={'eo:cloud_cover':{'lt':10},'platform':{'eq':'landsat-8'}},limit=1000)\n",
    "    ls30s=Raster(ls30.sel(band=['red', 'green', 'blue','nir08', 'lwir11','swir16', 'swir22'],x=slice(xmin,xmax),y=slice(ymax,ymin)))\n",
    "    ls30s=ls30s.save('ls82016.tif')\n",
    "\n",
    "#Load the Landsat raster\n",
    "ls30s=Raster('ls82016.tif')\n",
    "\n",
    "#get TCC data\n",
    "if(not os.path.exists('cf1.tif')): #if the 2016 tree canopy cover file does not exits, download it\n",
    "    url=r'https://www.mrlc.gov/geoserver/mrlc_download/nlcd_tcc_conus_2016_v2021-4/wcs?'\n",
    "    sn='mrlc_download__nlcd_tcc_conus_2016_v2021-4'\n",
    "    get_wcs_data(url=url,ply=nf1p,service_name=sn,out_prefix='cf1')\n",
    "\n",
    "\n",
    "#Load the TCC raster\n",
    "tcc_rs=Raster('cf1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely, xarray as xr, numba as nb\n",
    "\n",
    "#Create a random sample definition\n",
    "def get_random_sample(bnd, n=1000):\n",
    "    \"\"\"\n",
    "    produces a random sample given a geometry\n",
    "\n",
    "    parameters:\n",
    "    bnd = (GeoDataFrame or GeoSeries) project boundary\n",
    "    n = number of observations\n",
    "\n",
    "    returns: geodataframe of point locations\n",
    "\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bnd.total_bounds\n",
    "    xdif = xmax - xmin\n",
    "    ydif = ymax - ymin\n",
    "    pnts_lst = []\n",
    "    ubnd=bnd.unary_union\n",
    "    while len(pnts_lst) < n:\n",
    "        x = (np.random.random() * xdif) + xmin\n",
    "        y = (np.random.random() * ydif) + ymin\n",
    "        pnt = shapely.geometry.Point([x, y])\n",
    "        if pnt.intersects(ubnd):\n",
    "            pnts_lst.append(pnt)\n",
    "\n",
    "    dic = {\"geometry\": pnts_lst}\n",
    "    gdf = gpd.GeoDataFrame(dic, crs=bnd.crs)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True)\n",
    "def _expand_pnts_for_kernel(isys,isxs,wsize):\n",
    "    '''\n",
    "    Extracts values for kernel cells. Cells indices falling on the boundary of the image are moved in one index value.\n",
    "    isys=array of row index locations\n",
    "    isxs=array of column index locations\n",
    "    wsize=width of the kernel\n",
    "    \n",
    "    returns two new lists of index values kernel cell locations that can be used to extract coordinate from an xarray data array\n",
    "    '''\n",
    "    hw=int(wsize/2)\n",
    "    isys2=np.zeros(isys.shape[0]*wsize*wsize,dtype='int32')\n",
    "    isxs2=np.zeros(isxs.shape[0]*wsize*wsize,dtype='int32')\n",
    "    cnt=0\n",
    "    for r in range(isys.shape[0]):\n",
    "        rvl=isys[r]\n",
    "        cvl=isxs[r]\n",
    "        rvlm=rvl-hw\n",
    "        for r2 in range(wsize):\n",
    "            nr=rvlm+r2\n",
    "            cvlm=cvl-hw\n",
    "            for c2 in range(wsize):\n",
    "                nc=cvlm+c2\n",
    "                isys2[cnt]=nr\n",
    "                isxs2[cnt]=nc\n",
    "                cnt+=1\n",
    "\n",
    "    return isys2,isxs2\n",
    "\n",
    "def create_sample(bndr,r_rs,pred_rs,n,wsize=1):\n",
    "    '''\n",
    "    Creates a simple random sample of locations given a boundary and n and extracts response and predictor variables values for those location and the cell surrounding those locations.\n",
    "    bndr = GeoDataFrame or GeoSeries of the boundary\n",
    "    r_rs = response Raster object to be sampled\n",
    "    pred_rs= predictor Raster object to be sampled\n",
    "    n = (integer) sample size\n",
    "    wsize=(int) width of a square kernel in cells\n",
    "\n",
    "    returns a GeoDataFrame of response and predictor cell values\n",
    "    '''\n",
    "    pnts=get_random_sample(bndr,n=n)\n",
    "    xs=pnts.geometry.x\n",
    "    ys=pnts.geometry.y\n",
    "    rws=xs.shape[0]\n",
    "\n",
    "    #get response values\n",
    "    isys,isxs=r_rs.index(xs,ys)\n",
    "    rsel=r_rs.xdata.isel(x=xr.DataArray(isxs,dims='loc'),y=xr.DataArray(isys,dims='loc'))\n",
    "    rvls=pd.DataFrame(rsel.values.reshape((rws,1)),columns=['response'])\n",
    "\n",
    "    #get predictor values\n",
    "    isys,isxs=pred_rs.index(xs,ys)\n",
    "\n",
    "\n",
    "\n",
    "    if(wsize>1):\n",
    "        isys,isxs=_expand_pnts_for_kernel(isys.values,isxs.values,wsize)\n",
    "\n",
    "    sel=pred_rs.xdata.isel(x=xr.DataArray(isxs,dims='loc'),y=xr.DataArray(isys,dims='loc'))\n",
    "    pvls=sel.values.reshape((pred_rs.shape[0],rws,wsize*wsize))\n",
    "    clms=sel.shape[0]*wsize*wsize\n",
    "    pvls=pd.DataFrame(np.moveaxis(pvls,1,0).reshape(rws,clms),columns=['p' + str(sub) for sub in np.arange(clms)])\n",
    "\n",
    "    df=pd.concat([pnts,pvls,rvls],axis=1)\n",
    "    vls=df.dropna()#(df[df!=r_rs.null_value]).dropna()\n",
    "\n",
    "    return vls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hilbertcurve.hilbertcurve import HilbertCurve\n",
    "from sklearn.decomposition import PCA\n",
    "class hilbert:\n",
    "    def __init__(self):\n",
    "        self._p=None\n",
    "        self._d=None\n",
    "        self._hc = None\n",
    "        self.s_arr = None\n",
    "        self._pca=None\n",
    "        self._min=None\n",
    "        self._max=None\n",
    "\n",
    "    @property\n",
    "    def hilbert_mdl(self):\n",
    "        return self._hc\n",
    "    \n",
    "    def _transform(self,X):\n",
    "        if(self._pca is None):\n",
    "            self._sd=np.std(X,axis=0)\n",
    "            self._pca = PCA()\n",
    "            x2=X/self._sd\n",
    "            self._pca.fit(x2)\n",
    "        else:\n",
    "            x2=X/self._sd\n",
    "\n",
    "        x3=self._pca.transform(x2)\n",
    "        mlp=(2**self._p)-1\n",
    "        if(self._min is None):\n",
    "            self._min = np.min(x3)\n",
    "            self._max = np.max(x3)\n",
    "\n",
    "        vls=(((x3-self._min)/(self._max-self._min))*(mlp)).astype('uint32')\n",
    "        vls[vls>mlp]=mlp\n",
    "        vls[vls<0]=0\n",
    "        return vls\n",
    "    \n",
    "    def fit(self,X,y,p=8):\n",
    "        self._d=X.shape[1]\n",
    "        self._p=p\n",
    "        X2=self._transform(X)\n",
    "        self._hc = HilbertCurve(self._p,self._d)\n",
    "        hvls= np.array(self._hc.distances_from_points(X2)).astype('f8')\n",
    "        tarr = pd.DataFrame([hvls,y],index=['hilb','resp']).T.sort_values('hilb')\n",
    "        vls=tarr.groupby('hilb').mean().reset_index().values#.agg(['mean','count']).reset_index().values #\n",
    "        self.s_arr = vls\n",
    "\n",
    "    def predict(self,X):\n",
    "        X2=self._transform(X)\n",
    "        X3=np.array(self._hc.distances_from_points(X2)).astype('f8')\n",
    "        return _impute_hc_f(X3,self.s_arr)\n",
    "        \n",
    "nb.jit(nopython=True, nogil=True)\n",
    "def _get_hc(v,s_array):\n",
    "    dic={}\n",
    "    for r in range(s_array.shape[0]):\n",
    "        ind,vl=s_array[r,:]\n",
    "        if(v==ind):\n",
    "            outvl=vl\n",
    "            return outvl\n",
    "        else:\n",
    "            ind2=int(ind/2)\n",
    "            if(ind2 in dic):\n",
    "                j,k=dic[ind2]\n",
    "                j+=vl\n",
    "                k+=1\n",
    "                dic[ind2] = [j,k]\n",
    "            else:\n",
    "                dic[ind2] = [vl,1]\n",
    "    s_array2=np.zeros((len(dic),2))\n",
    "    cnt=0\n",
    "    for ky,vl in dic.items():\n",
    "        s_array2[cnt,:]=[ky,vl[0]/vl[1]]\n",
    "        cnt+=1\n",
    "\n",
    "    outvl=_get_hc(int(v/2),s_array2)\n",
    "\n",
    "    return outvl\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    # ind=np.searchsorted(s_array[:,0],v)\n",
    "    # if(ind>=s_array.shape[0]):\n",
    "    #     outvl=s_array[-1,1]\n",
    "    # elif(ind==0):\n",
    "    #     outvl=s_array[0,1]\n",
    "    # else:\n",
    "    #     kyu,vlu=s_array[ind,:]\n",
    "    #     if(kyu==v):\n",
    "    #         outvl=vlu\n",
    "    #     else:\n",
    "    #         ind2=ind-1\n",
    "    #         kyl,vll=s_array[ind2,:]\n",
    "    #         # r=(vlu-vll)/(kyu-kyl)\n",
    "    #         # outvl=vll+(v-kyl)*r\n",
    "    #         dl=1/(v-kyl)\n",
    "    #         du=1/(kyu-v)\n",
    "    #         outvl=(vll*dl+vlu*du)/(dl+du)#((vll*dl*cl)+(vlu*du*cu))/((dl+du)*(cl+cu))\n",
    "    #         #try using scale and bit math\n",
    "    # 0return outvl..\n",
    "\n",
    "nb.jit(nopython=True, nogil=True)\n",
    "def _impute_hc_f(X,s_arr):\n",
    "    rws=X.shape[0]\n",
    "    out_arr=np.zeros((rws,1))\n",
    "    for r in range(rws):\n",
    "        v=X[r]\n",
    "        outvl=_get_hc(v,s_arr)   \n",
    "        out_arr[r]=outvl\n",
    "    return out_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples\n",
    "ksize=1\n",
    "pnts2=create_sample(nf1p,r_rs=tcc_rs,pred_rs=ls30s,n=150,wsize=ksize)\n",
    "pnts2['response']=pnts2['response']\n",
    "pnts2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training dataset\n",
    "tdf_train = pnts2.sample(110)\n",
    "tdf_val=pnts2.iloc[~pnts2.index.isin(tdf_train.index)].copy()\n",
    "print('Training Data')\n",
    "print('Response std =',tdf_train['response'].std())\n",
    "\n",
    "#create hibert curve model\n",
    "hc=hilbert()\n",
    "pred_ls = pnts2.columns[1:-1]\n",
    "resp=pnts2.columns[-1]\n",
    "X=tdf_train[pred_ls].values\n",
    "y=tdf_train[resp].values\n",
    "hc.fit(X,y,8)\n",
    "\n",
    "X2=tdf_val[pred_ls].values\n",
    "pred=hc.predict(X2)\n",
    "tdf_val['pred']=pred\n",
    "tdf_train['pred']=hc.predict(tdf_train[pred_ls].values)\n",
    "\n",
    "evdf=tdf_train[['response','pred']]\n",
    "print('RMSE =',np.sqrt(((evdf['response']-evdf['pred'])**2).mean()))\n",
    "print('train r2 =',(evdf.corr()).iloc[0,1]**2)\n",
    "p = evdf.plot(kind='scatter',x='pred',y='response',title=\"Train Data Observed vs Predicted\",figsize=(8,8))\n",
    "p.axline((0, 0), slope=1,color='grey')\n",
    "display(p)\n",
    "\n",
    "#validation dataset\n",
    "print('Response std =',tdf_val['response'].std())\n",
    "evdf=tdf_val[['response','pred']]\n",
    "print('RMSE =',np.sqrt(((evdf['response']-evdf['pred'])**2).mean()))\n",
    "print('val r2 =',(evdf.corr()).iloc[0,1]**2)\n",
    "p = evdf.plot(kind='scatter',x='pred',y='response',title=\"Validation Data Observed vs Predicted\",figsize=(8,8))\n",
    "p.axline((0, 0), slope=1,color='grey')\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg2 = RandomForestRegressor(n_estimators=50,max_samples=0.75,random_state=0)\n",
    "X=tdf_train[pred_ls].values\n",
    "y=tdf_train['response'].values\n",
    "reg2.fit(X,y)\n",
    "\n",
    "pred=reg2.predict(tdf_val[pred_ls].values)\n",
    "tdf_val['pred']=pred\n",
    "tdf_train['pred']=reg2.predict(tdf_train[pred_ls].values)\n",
    "#training dataset\n",
    "print('Training Data')\n",
    "print('Response std =',tdf_train['response'].std())\n",
    "evdf=tdf_train[['response','pred']]\n",
    "print('RMSE =',np.sqrt(((evdf['response']-evdf['pred'])**2).mean()))\n",
    "print('train r2 =',(evdf.corr()).iloc[0,1]**2)\n",
    "p = evdf.plot(kind='scatter',x='pred',y='response',title=\"Train Data Observed vs Predicted\",figsize=(8,8))\n",
    "p.axline((0, 0), slope=1,color='grey')\n",
    "display(p)\n",
    "\n",
    "#validation dataset\n",
    "print('Response std =',tdf_val['response'].std())\n",
    "evdf=tdf_val[['response','pred']]\n",
    "print('RMSE =',np.sqrt(((evdf['response']-evdf['pred'])**2).mean()))\n",
    "print('val r2 =',(evdf.corr()).iloc[0,1]**2)\n",
    "p = evdf.plot(kind='scatter',x='pred',y='response',title=\"Validation Data Observed vs Predicted\",figsize=(8,8))\n",
    "p.axline((0, 0), slope=1,color='grey')\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg2 = LinearRegression().fit(X, y)\n",
    "\n",
    "X=tdf_train[pred_ls].values\n",
    "y=tdf_train['response'].values\n",
    "reg2.fit(X,y)\n",
    "\n",
    "pred=reg2.predict(tdf_val[pred_ls].values)\n",
    "tdf_val['pred']=pred\n",
    "tdf_train['pred']=reg2.predict(tdf_train[pred_ls].values)\n",
    "#training dataset\n",
    "print('Training Data')\n",
    "print('Response std =',tdf_train['response'].std())\n",
    "evdf=tdf_train[['response','pred']]\n",
    "print('RMSE =',np.sqrt(((evdf['response']-evdf['pred'])**2).mean()))\n",
    "print('train r2 =',(evdf.corr()).iloc[0,1]**2)\n",
    "p = evdf.plot(kind='scatter',x='pred',y='response',title=\"Train Data Observed vs Predicted\",figsize=(8,8))\n",
    "p.axline((0, 0), slope=1,color='grey')\n",
    "display(p)\n",
    "\n",
    "#validation dataset\n",
    "print('Response std =',tdf_val['response'].std())\n",
    "evdf=tdf_val[['response','pred']]\n",
    "print('RMSE =',np.sqrt(((evdf['response']-evdf['pred'])**2).mean()))\n",
    "print('val r2 =',(evdf.corr()).iloc[0,1]**2)\n",
    "p = evdf.plot(kind='scatter',x='pred',y='response',title=\"Validation Data Observed vs Predicted\",figsize=(8,8))\n",
    "p.axline((0, 0), slope=1,color='grey')\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_rs=ls30s.model_predict(hc)\n",
    "hc_rs.plot(robust=True,figsize=(15,8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rstools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
